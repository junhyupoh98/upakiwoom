from flask import Flask, jsonify, request
from flask_cors import CORS
import FinanceDataReader as fdr
from datetime import datetime, timedelta, timezone
import pandas as pd
import requests
import time
import re
import difflib
import os
import json
from urllib.parse import urlencode, urlparse
from typing import List, Dict, Optional, Union, Any, Tuple
from deep_translator import GoogleTranslator
from openai import OpenAI
from newspaper import Article, ArticleException
from concurrent.futures import ThreadPoolExecutor, as_completed
from dotenv import load_dotenv

try:
    from .chroma_client import (
        fetch_us_stock_news,
        fetch_kr_stock_news,
        fetch_us_financials_from_chroma,
        fetch_kr_financials_from_chroma,
    )
except ImportError:
    from chroma_client import (  # type: ignore
        fetch_us_stock_news,
        fetch_kr_stock_news,
        fetch_us_financials_from_chroma,
        fetch_kr_financials_from_chroma,
    )

try:
    from .vision_bridge import analyze_product_from_image
except ImportError:
    from vision_bridge import analyze_product_from_image  # type: ignore
from pathlib import Path
load_dotenv(Path(__file__).resolve().parent.parent / ".env")
# DART APIëŠ” requestsë¡œ ì§ì ‘ í˜¸ì¶œ

app = Flask(__name__)
CORS(app)

# FMP API í‚¤ (ë¬´ë£Œ í‹°ì–´ ì‚¬ìš©)
FMP_API_KEY = os.getenv("FMP_API_KEY")
# DART API í‚¤ (https://opendart.fss.or.kr/ ì—ì„œ ë°œê¸‰ í•„ìš”)
DART_API_KEY = os.getenv("DART_API_KEY")
# ë„¤ì´ë²„ ë‰´ìŠ¤ API í‚¤
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# API í‚¤ ì„¤ì • ìƒíƒœ ë¡œê·¸
if FMP_API_KEY:
    print('[OK] FMP API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
else:
    print('[WARN] FMP API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë¶€ í•´ì™¸ ë°ì´í„°ê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')

# DART API ì´ˆê¸°í™” í™•ì¸
if DART_API_KEY:
    print('[OK] DART API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
else:
    print('[WARN] DART API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')

if NAVER_CLIENT_ID and NAVER_CLIENT_SECRET:
    print('[OK] ë„¤ì´ë²„ ë‰´ìŠ¤ API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.')
else:
    print('[WARN] ë„¤ì´ë²„ ë‰´ìŠ¤ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = None
if OPENAI_API_KEY:
    try:
        openai_client = OpenAI(api_key=OPENAI_API_KEY)
        print(f'[OK] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ')
    except Exception as e:
        print(f'[ERROR] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}')
        openai_client = None
else:
    print('[WARN] OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìš”ì•½ ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')

# í•œêµ­ ì£¼ì‹ ì‹¬ë³¼ ì½”ë“œ ë§¤í•‘ (ì¼ë¶€ ì£¼ìš” ì¢…ëª©)
KR_STOCK_MAP = {
    'ì‚¼ì„±ì „ì': '005930',
    'SKí•˜ì´ë‹‰ìŠ¤': '000660',
    'NAVER': '035420',
    'ì¹´ì¹´ì˜¤': '035720',
    'LGí™”í•™': '051910',
    'íŠ¸ëœìŠ¤ì˜¤ì…˜': '065350',
    'ì—ìŠ¤ë¹„ë¹„í…Œí¬': '389500',
    'í˜„ëŒ€ì°¨': '005380',
    'ê¸°ì•„': '000270',
    'ì…€íŠ¸ë¦¬ì˜¨': '068270',
}

def search_kr_stock_symbol(query):
    """íšŒì‚¬ëª…ìœ¼ë¡œ ì‹¬ë³¼ ì½”ë“œ ì°¾ê¸°"""
    # ê³µë°± ì œê±° (ì˜ˆ: "ì›ìµ í™€ë”©ìŠ¤" â†’ "ì›ìµí™€ë”©ìŠ¤")
    query_normalized = query.strip().replace(' ', '').replace('\t', '')
    print(f'ì¢…ëª© ê²€ìƒ‰ ì‹œì‘: "{query_normalized}" (ì›ë³¸: "{query}")')
    
    # ìˆ«ì 6ìë¦¬ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if query_normalized.isdigit() and len(query_normalized) == 6:
        print(f'ì¢…ëª©ì½”ë“œë¡œ ì¸ì‹: {query_normalized}')
        return query_normalized
    
    # FinanceDataReaderë¡œ ë¨¼ì € ê²€ìƒ‰ (ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ìš°ì„ )
    try:
        print(f'KRX ë¦¬ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹œë„: {query_normalized}')
        # KRX ìƒì¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)
        krx_list = get_krx_list_cached()
        if krx_list is not None and not krx_list.empty:
            print(f'KRX ë¦¬ìŠ¤íŠ¸ í¬ê¸°: {len(krx_list)}')
            # ì •í™•í•œ ë§¤ì¹­ ë¨¼ì € ì‹œë„
            symbol_col = 'Code' if 'Code' in krx_list.columns else ('Symbol' if 'Symbol' in krx_list.columns else None)
            name_col = 'Name' if 'Name' in krx_list.columns else 'ì¢…ëª©ëª…'
            
            if symbol_col:
                # ì •í™•í•œ ì´ë¦„ ë§¤ì¹­
                exact_match = krx_list[krx_list[name_col].str.strip().str.lower() == query_normalized.lower()]
                if not exact_match.empty:
                    found_symbol = str(exact_match.iloc[0][symbol_col]).zfill(6)
                    found_name = exact_match.iloc[0][name_col]
                    print(f'KRX ì •í™• ë§¤ì¹­ ì„±ê³µ: {found_name} ({found_symbol})')
                    return found_symbol
                
                # ë¶€ë¶„ ë§¤ì¹­ (íšŒì‚¬ëª…ì— í¬í•¨ëœ ê²½ìš°)
                result = krx_list[krx_list[name_col].str.contains(query_normalized, case=False, na=False)]
                print(f'ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(result)}')
                if not result.empty:
                    found_symbol = str(result.iloc[0][symbol_col]).zfill(6)
                    found_name = result.iloc[0][name_col]
                    print(f'KRXì—ì„œ ì°¾ì€ ì¢…ëª©: {found_name} ({found_symbol})')
                    return found_symbol
                else:
                    print(f'KRX ë¦¬ìŠ¤íŠ¸ì—ì„œ "{query_normalized}"ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ')
            else:
                print('KRX ë¦¬ìŠ¤íŠ¸ì— ì¢…ëª©ì½”ë“œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤')
        else:
            print('KRX ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ')
    except Exception as e:
        print(f'KRX ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}')
        import traceback
        traceback.print_exc()
    
    # KRX ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œì—ë§Œ í•˜ë“œì½”ë”©ëœ ë§¤í•‘ í™•ì¸ (í´ë°±)
    print(f'í•˜ë“œì½”ë”© ë§¤í•‘ í™•ì¸ (í´ë°±): {query_normalized}')
    query_lower = query_normalized.lower()
    for name, symbol in KR_STOCK_MAP.items():
        # ì •í™•í•œ ë§¤ì¹­ë§Œ í™•ì¸ (ë¶€ë¶„ ë§¤ì¹­ ì œê±°)
        if query_normalized == name or query_lower == name.lower():
            print(f'í•˜ë“œì½”ë”© ë§¤í•‘ì—ì„œ ì°¾ìŒ: {name} -> {symbol}')
            return symbol
    
    return None

@app.route('/api/kr-stock/search/<query>', methods=['GET'])
def search_stock(query):
    """íšŒì‚¬ëª…ìœ¼ë¡œ í•œêµ­ ì£¼ì‹ ê²€ìƒ‰"""
    try:
        print(f'ê²€ìƒ‰ ìš”ì²­: {query}')
        symbol = search_kr_stock_symbol(query)
        print(f'ì°¾ì€ ì‹¬ë³¼: {symbol}')
        
        if not symbol:
            print(f'ì‹¬ë³¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {query}')
            return jsonify({'error': f'"{query}"ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # ì£¼ê°€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        print(f'ì£¼ê°€ ì •ë³´ ì¡°íšŒ ì‹œì‘: {symbol}')
        # ìµœê·¼ 1ë…„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365)
        df = fdr.DataReader(symbol, start_date, end_date)
        if df is None or df.empty:
            print(f'ì£¼ê°€ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ: {symbol}')
            return jsonify({'error': 'ì£¼ê°€ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500
        print(f'ì£¼ê°€ ì •ë³´ ì¡°íšŒ ì„±ê³µ: {symbol} (ë°ì´í„° ìˆ˜: {len(df)})')
        
        latest = df.iloc[-1]
        previous = df.iloc[-2] if len(df) > 1 else latest
        
        change = float(latest['Close'] - previous['Close'])
        change_percent = float((change / previous['Close']) * 100) if previous['Close'] != 0 else 0
        
        # íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸° (ê²€ìƒ‰ ê³¼ì •ì—ì„œ ì´ë¯¸ ì°¾ì•˜ìœ¼ë¯€ë¡œ ì¬ê²€ìƒ‰ ë¶ˆí•„ìš”)
        company_name = query
        # ë§¤í•‘ì—ì„œ ì°¾ì€ ê²½ìš° íšŒì‚¬ëª… ì‚¬ìš©
        if symbol in KR_STOCK_MAP.values():
            for name, sym in KR_STOCK_MAP.items():
                if sym == symbol:
                    company_name = name
                    break
        else:
            # KRX ë¦¬ìŠ¤íŠ¸ì—ì„œ íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)
            try:
                krx_list = get_krx_list_cached()
                if krx_list is not None and not krx_list.empty:
                    # ì»¬ëŸ¼ëª… í™•ì¸ (Symbol ë˜ëŠ” Codeì¼ ìˆ˜ ìˆìŒ)
                    symbol_col = 'Symbol' if 'Symbol' in krx_list.columns else 'Code'
                    name_col = 'Name' if 'Name' in krx_list.columns else 'ì¢…ëª©ëª…'
                    company_info = krx_list[krx_list[symbol_col] == symbol]
                    if not company_info.empty:
                        company_name = company_info.iloc[0][name_col]
            except Exception as e:
                print(f'íšŒì‚¬ëª… ì¡°íšŒ ì˜¤ë¥˜: {str(e)}')
                pass
        
        # ë‰´ìŠ¤ëŠ” ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ ê°€ì ¸ì˜¤ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œì™¸
        result = {
            'symbol': f'{symbol}.KS',
            'name': company_name,
            'price': float(latest['Close']),
            'change': float(change),
            'changePercent': round(change_percent, 2),
            'volume': int(latest['Volume']) if 'Volume' in latest else 0,
            'open': float(latest['Open']),
            'high': float(latest['High']),
            'low': float(latest['Low']),
            'currency': 'KRW',
            'exchange': 'KRX',
            'isKorean': True
        }
        
        return jsonify(result)
    except Exception as e:
        import traceback
        print(f'ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}')
        traceback.print_exc()
        return jsonify({'error': f'ì£¼ê°€ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/api/kr-stock/<symbol>', methods=['GET'])
def get_stock(symbol):
    """ì‹¬ë³¼ ì½”ë“œë¡œ í•œêµ­ ì£¼ì‹ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # ì‹¬ë³¼ ì½”ë“œ ì •ë¦¬ (.KS ì œê±°)
        clean_symbol = symbol.replace('.KS', '').replace('.KQ', '')
        
        if not clean_symbol.isdigit() or len(clean_symbol) != 6:
            return jsonify({'error': 'ì˜¬ë°”ë¥¸ ì‹¬ë³¼ ì½”ë“œê°€ ì•„ë‹™ë‹ˆë‹¤.'}), 400
        
        # ì£¼ê°€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365)
        df = fdr.DataReader(clean_symbol, start_date, end_date)
        if df is None or df.empty:
            return jsonify({'error': 'ì£¼ê°€ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500
        
        latest = df.iloc[-1]
        previous = df.iloc[-2] if len(df) > 1 else latest
        
        change = float(latest['Close'] - previous['Close'])
        change_percent = float((change / previous['Close']) * 100) if previous['Close'] != 0 else 0
        
        # íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)
        krx_list = get_krx_list_cached()
        company_name = clean_symbol
        if krx_list is not None and not krx_list.empty:
            symbol_col = 'Symbol' if 'Symbol' in krx_list.columns else 'Code'
            name_col = 'Name' if 'Name' in krx_list.columns else 'ì¢…ëª©ëª…'
            company_info = krx_list[krx_list[symbol_col] == clean_symbol]
            if not company_info.empty:
                company_name = company_info.iloc[0][name_col]
        
        result = {
            'symbol': f'{clean_symbol}.KS',
            'name': company_name,
            'price': float(latest['Close']),
            'change': float(change),
            'changePercent': round(change_percent, 2),
            'volume': int(latest['Volume']) if 'Volume' in latest else 0,
            'open': float(latest['Open']),
            'high': float(latest['High']),
            'low': float(latest['Low']),
            'currency': 'KRW',
            'exchange': 'KRX',
            'isKorean': True
        }
        
        return jsonify(result)
    except Exception as e:
        print(f'ì˜¤ë¥˜: {str(e)}')
        return jsonify({'error': f'ì£¼ê°€ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/api/kr-stock/<symbol>/chart', methods=['GET'])
def get_stock_chart(symbol):
    """í•œêµ­ ì£¼ì‹ ì°¨íŠ¸ ë°ì´í„°"""
    try:
        period = request.args.get('period', '1m')
        clean_symbol = symbol.replace('.KS', '').replace('.KQ', '')
        
        # ê¸°ê°„ ì„¤ì •
        if period == '1m':
            start_date = datetime.now() - timedelta(days=30)
        elif period == '3m':
            start_date = datetime.now() - timedelta(days=90)
        elif period == '6m':
            start_date = datetime.now() - timedelta(days=180)
        elif period == '1y':
            start_date = datetime.now() - timedelta(days=365)
        else:
            start_date = datetime.now() - timedelta(days=30)
        
        # ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        end_date = datetime.now()
        df = fdr.DataReader(clean_symbol, start_date, end_date)
        if df is None or df.empty:
            return jsonify({'error': 'ì°¨íŠ¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500
        
        chart_data = []
        for idx, row in df.iterrows():
            chart_data.append({
                'date': idx.strftime('%Y-%m-%d'),
                'open': float(row['Open']),
                'high': float(row['High']),
                'low': float(row['Low']),
                'close': float(row['Close']),
                'volume': int(row['Volume']) if 'Volume' in row else 0
            })
        
        return jsonify({
            'symbol': f'{clean_symbol}.KS',
            'period': period,
            'data': chart_data
        })
    except Exception as e:
        print(f'ì°¨íŠ¸ ì˜¤ë¥˜: {str(e)}')
        return jsonify({'error': f'ì°¨íŠ¸ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

# ============ ë„¤ì´ë²„ ë‰´ìŠ¤ API ì„¤ì • ============
NAVER_NEWS_API_URL = "https://openapi.naver.com/v1/search/news.json"
NAVER_NEWS_TARGET_COUNT = 10
NAVER_NEWS_RECENT_DAYS = 60
NAVER_NEWS_PER_PAGE = 100
NAVER_NEWS_MAX_PAGES = 5
NAVER_NEWS_SLEEP_SEC = 0.03

# í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸(ë„ë©”ì¸)
NAVER_WHITELIST = {
    "chosun.com": "ì¡°ì„ ì¼ë³´",
    "joongang.co.kr": "ì¤‘ì•™ì¼ë³´",
    "donga.com": "ë™ì•„ì¼ë³´",
    "kyunghyang.com": "ê²½í–¥ì‹ ë¬¸",
    "hani.co.kr": "í•œê²¨ë ˆ",
    "hankookilbo.com": "í•œêµ­ì¼ë³´",
    "mk.co.kr": "ë§¤ì¼ê²½ì œ",
    "hankyung.com": "í•œêµ­ê²½ì œ",
    "sedaily.com": "ì„œìš¸ê²½ì œ",
    "mt.co.kr": "ë¨¸ë‹ˆíˆ¬ë°ì´",
    "fnnews.com": "íŒŒì´ë‚¸ì…œë‰´ìŠ¤",
    "asiae.co.kr": "ì•„ì‹œì•„ê²½ì œ",
}
NAVER_WHITELIST_KEYS = set(NAVER_WHITELIST.keys())

PRESS_TO_DOMAIN = {
    "ì¡°ì„ ì¼ë³´": "chosun.com",
    "ì¤‘ì•™ì¼ë³´": "joongang.co.kr",
    "ë™ì•„ì¼ë³´": "donga.com",
    "ê²½í–¥ì‹ ë¬¸": "kyunghyang.com",
    "í•œê²¨ë ˆ": "hani.co.kr",
    "í•œêµ­ì¼ë³´": "hankookilbo.com",
    "ë§¤ì¼ê²½ì œ": "mk.co.kr",
    "í•œêµ­ê²½ì œ": "hankyung.com",
    "ì„œìš¸ê²½ì œ": "sedaily.com",
    "ë¨¸ë‹ˆíˆ¬ë°ì´": "mt.co.kr",
    "íŒŒì´ë‚¸ì…œë‰´ìŠ¤": "fnnews.com",
    "ì•„ì‹œì•„ê²½ì œ": "asiae.co.kr",
}

# ì–¸ë¡ ì‚¬ ì¶”ì • íŒ¨í„´
PRESS_META_PATTERNS = [
    re.compile(r'property=["\']og:article:author["\']\s+content=["\']([^"\']{2,20})["\']', re.I),
    re.compile(r'data-office-name=["\']([^"\']{2,20})["\']', re.I),
    re.compile(r'aria-label=["\']([^"\']{2,20})["\']', re.I),
    re.compile(r'"press_logo"[^>]*alt=["\']([^"\']{2,20})["\']', re.I),
]

# HTML íƒœê·¸ ì œê±° ì •ê·œì‹
_TAG = re.compile(r"<.*?>")
_WS = re.compile(r"\s+")

KST = timezone(timedelta(hours=9))

# ë„¤ì´ë²„ ë‰´ìŠ¤ ìœ í‹¸ í•¨ìˆ˜
def clean_html_naver(s: str) -> str:
    """HTML íƒœê·¸ ì œê±°"""
    if not s:
        return ""
    s = _TAG.sub(" ", s).replace("&quot;", '"').replace("&apos;", "'").replace("&amp;", "&")
    return _WS.sub(" ", s).strip()

def parse_dt_naver(rfc822_text: Optional[str]) -> Optional[datetime]:
    """RFC822 ë‚ ì§œ íŒŒì‹±"""
    if not rfc822_text:
        return None
    try:
        dt = datetime.strptime(rfc822_text, "%a, %d %b %Y %H:%M:%S %z")
        return dt.astimezone(KST)
    except Exception:
        return None

def netloc_domain_naver(url: str) -> str:
    """URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ"""
    try:
        netloc = urlparse(url).netloc.lower().replace("www.", "")
        return netloc
    except Exception:
        return ""

def normalize_korean_naver(s: str) -> str:
    """í•œê¸€ ì •ê·œí™”"""
    return re.sub(r"[\s\W_]+", "", s or "").lower()

def contains_company_naver(text: str, company: str) -> bool:
    """íšŒì‚¬ëª… í¬í•¨ ì—¬ë¶€ í™•ì¸"""
    if not text or not company:
        return False
    base = company.strip()
    no_space = normalize_korean_naver(base)
    if re.search(re.escape(base), text, flags=re.IGNORECASE):
        return True
    if no_space and no_space in normalize_korean_naver(text):
        return True
    if re.search(r"(?:\(\s*ì£¼\s*\)\s*)?" + re.escape(base), text, flags=re.IGNORECASE):
        return True
    return False

def infer_press_from_naver(link: str, timeout: int = 4) -> Optional[str]:
    """ë„¤ì´ë²„ ë§í¬ì—ì„œ ì–¸ë¡ ì‚¬ ì¶”ì •"""
    if not link:
        return None
    try:
        r = requests.get(link, headers={"User-Agent": "Mozilla/5.0"}, timeout=timeout)
        if r.status_code >= 400:
            return None
        text = r.text[:200000]
        for pat in PRESS_META_PATTERNS:
            m = pat.search(text)
            if m:
                press = m.group(1).strip()
                press = re.sub(r"[\s\u200b]+", "", press)
                return press
    except Exception:
        return None
    return None

def summarize_naver_news(title: str, desc: str) -> str:
    """OpenAIë¡œ ë‰´ìŠ¤ ìš”ì•½"""
    if not openai_client:
        return desc or ""
    prompt = f"""
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ 6~8ì¤„ bullet ìš”ì•½ì„ ë§Œë“¤ì–´ì¤˜.
- í™•ì¸ëœ ì‚¬ì‹¤/ìˆ«ì/ì£¼ì²´ ì¤‘ì‹¬, ê³¼ì¥/ì¶”ì¸¡ ê¸ˆì§€
- ê° ì¤„ 20~40ìê¶Œ, ì¤‘ë³µ/ê´‘ê³  ì œê±°

ì œëª©: {title}
ìš”ì•½ë¬¸: {desc}
"""
    try:
        resp = openai_client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ê²½ì œÂ·ê¸ˆìœµ ë‰´ìŠ¤ë¥¼ ì •í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ëŠ” ë¶„ì„ê°€"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=420,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        print(f"[WARN] ìš”ì•½ ì‹¤íŒ¨: {e}")
        return desc or ""

def fetch_naver_news_raw(query: str, start: int, display: int, sort: str) -> List[Dict]:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ"""
    if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
        return []
    headers = {"X-Naver-Client-Id": NAVER_CLIENT_ID, "X-Naver-Client-Secret": NAVER_CLIENT_SECRET}
    params = {"query": query, "display": display, "start": start, "sort": sort}
    url = f"{NAVER_NEWS_API_URL}?{urlencode(params, safe=':/')}"
    try:
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code == 429:
            print(f"[WARN] ë„¤ì´ë²„ API í˜¸ì¶œ ì œí•œ ë„ë‹¬ (429), ì ì‹œ ëŒ€ê¸°...")
            time.sleep(0.5)
            return []
        r.raise_for_status()
        data = r.json()
        return data.get("items", [])
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] ë„¤ì´ë²„ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return []
    except Exception as e:
        print(f"[ERROR] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return []

def collect_naver_news(company: str, sort: str = "sim") -> List[Dict]:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ (ìµœì í™”: ìš”ì•½ ìƒëµ, ì–¸ë¡ ì‚¬ ì¶”ì • ìµœì†Œí™”)"""
    query = f'"{company}"'
    cutoff = datetime.now(KST) - timedelta(days=NAVER_NEWS_RECENT_DAYS)
    rows: List[Dict] = []
    seen = set()
    start = 1

    print(f'ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘: {query} (ìµœëŒ€ {NAVER_NEWS_TARGET_COUNT}ê°œ)')

    for page in range(1, NAVER_NEWS_MAX_PAGES + 1):
        items = fetch_naver_news_raw(query, start=start, display=NAVER_NEWS_PER_PAGE, sort=sort)
        if not items:
            break

        got_this_page = 0
        for it in items:
            title = clean_html_naver(it.get("title"))
            desc = clean_html_naver(it.get("description"))
            link = it.get("link") or ""
            origin = it.get("originallink") or ""
            pubdt = parse_dt_naver(it.get("pubDate"))
            if pubdt and pubdt < cutoff:
                continue

            key = origin or link
            if not key or key in seen:
                continue
            seen.add(key)

            # íšŒì‚¬ëª… í•„í„°
            if not (contains_company_naver(title, company) or contains_company_naver(desc, company)):
                continue

            # ë§¤ì²´ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ (ë¹ ë¥¸ ì²´í¬)
            host = netloc_domain_naver(origin)
            press_name = None
            domain_ok = False
            
            # ì›ë³¸ ë§í¬ì—ì„œ ë°”ë¡œ í™•ì¸
            if host in NAVER_WHITELIST_KEYS:
                domain_ok = True
                press_name = NAVER_WHITELIST[host]
            else:
                # ë„¤ì´ë²„ ë§í¬ì¸ ê²½ìš°ì—ë§Œ ì–¸ë¡ ì‚¬ ì¶”ì • ì‹œë„ (ëŠë¦° ì‘ì—…)
                naver_host = netloc_domain_naver(link)
                if naver_host.endswith("naver.com") and len(rows) < NAVER_NEWS_TARGET_COUNT:
                    # ìµœëŒ€ 10ê°œë§Œ ì–¸ë¡ ì‚¬ ì¶”ì • (ëŠë¦° ì‘ì—…)
                    press_name = infer_press_from_naver(link, timeout=2)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
                    if press_name and press_name in PRESS_TO_DOMAIN:
                        mapped = PRESS_TO_DOMAIN[press_name]
                        if mapped in NAVER_WHITELIST_KEYS:
                            domain_ok = True
                            host = mapped

            if not domain_ok:
                continue

            # ìš”ì•½ì€ ë‚˜ì¤‘ì— ë˜ëŠ” ìƒëµ (ì†ë„ ìš°ì„ )
            # summary = summarize_naver_news(title, desc)  # ëŠë¦° ì‘ì—… - ìƒëµ
            summary = desc or ""  # ì›ë³¸ ìš”ì•½ë¬¸ ì‚¬ìš©
            date_kst = pubdt.strftime("%Y-%m-%d %H:%M") if pubdt else ""

            rows.append({
                'title': title,
                'summary': summary,
                'url': origin or link,
                'date': date_kst,
                'site': press_name or NAVER_WHITELIST.get(host, host)
            })
            got_this_page += 1

            print(f'  [{len(rows):02d}] {date_kst} | {press_name or NAVER_WHITELIST.get(host, host)} | {title[:50]}...')

            if len(rows) >= NAVER_NEWS_TARGET_COUNT:
                print(f'ë„¤ì´ë²„ ë‰´ìŠ¤ {len(rows)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ')
                return rows

        if got_this_page == 0:
            break

        start += len(items)
        time.sleep(NAVER_NEWS_SLEEP_SEC)

    print(f'ë„¤ì´ë²„ ë‰´ìŠ¤ {len(rows)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ')
    return rows

# ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜
def get_fmp_stock_news(ticker, api_key, limit=20):
    """FMP APIë¡œ ì£¼ì‹ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    print(f"\n--- [FMP] {ticker} ìµœì‹  ë‰´ìŠ¤ {limit}ê°œ ê²€ìƒ‰ ---")
    url = f"https://financialmodelingprep.com/api/v3/stock_news?tickers={ticker}&limit={limit}&apikey={api_key}"
    try:
        res = requests.get(url, timeout=10)
        res.raise_for_status()
        data = res.json()
        if not data:
            print("ë‰´ìŠ¤ ì—†ìŒ.")
            return []
        return data
    except Exception as e:
        print(f"FMP API ì˜¤ë¥˜: {e}")
        return []

# ë²ˆì—­ í•¨ìˆ˜
def translate_text(text, dest_lang='ko'):
    """í…ìŠ¤íŠ¸ ë²ˆì—­"""
    if not text:
        return ""
    MAX_CHARS = 4800
    text = text[:MAX_CHARS] if len(text) > MAX_CHARS else text
    try:
        time.sleep(0.5)
        return GoogleTranslator(source='auto', target=dest_lang).translate(text)
    except Exception:
        return "ë²ˆì—­ ì‹¤íŒ¨"

# ChatGPT ìš”ì•½ í•¨ìˆ˜
def summarize_with_chatgpt(text):
    """ChatGPTë¡œ ë‰´ìŠ¤ ìš”ì•½ (ì›ë³¸ ë¡œì§ ì‚¬ìš©)"""
    if not text or text == "ë²ˆì—­ ì‹¤íŒ¨":
        return None
    if not openai_client:
        return None
    try:
        system_prompt = (
            "ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ì˜ ìµœê³  ê¸ˆìœµ ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. **ìµœìƒì˜ ì •í™•ì„±**ì„ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.\n"
            "ì œê³µëœ í•œêµ­ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì„ ë¶„ì„í•˜ì—¬, íˆ¬ììê°€ ì•Œì•„ì•¼ í•  **ê°€ì¥ ì¤‘ìš”í•˜ê³  ì •í™•í•œ ì •ë³´**ë§Œì„ ì¶”ì¶œí•˜ì—¬ **4~5 ë¬¸ì¥ì˜ ì •ë°€í•œ ìš”ì•½ë¬¸**ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"
            "**ğŸš¨ ìµœìš°ì„  ì£¼ì˜ì‚¬í•­ (ì¹˜ëª…ì  ì˜¤ë¥˜ ë°©ì§€):**\n"
            "**1. ëª¨ë“  ìˆ˜ì¹˜, ë‚ ì§œ, í†µí™”($, ì›), ì œí’ˆ ì´ë¦„ ë“± êµ¬ì²´ì  ê·¼ê±°ë¥¼ ì›ë¬¸ê³¼ 100% ì¼ì¹˜ì‹œì¼œì•¼ í•©ë‹ˆë‹¤. ì ˆëŒ€ë¡œ ì¶”ì¸¡í•˜ê±°ë‚˜ í‹€ë¦° ì •ë³´ë¥¼ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.**\n"
            "**2. ê¸°ì‚¬ì— ëª…ì‹œë˜ì§€ ì•Šì€ ë¯¸ë˜ ì „ë§(ì˜ˆ: 2025ë…„ 3ë¶„ê¸°)ì´ë‚˜ ê°œì¸ì ì¸ ì˜ê²¬ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ ê²ƒ.**\n\n"
            "**ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•  ë‚´ìš©:**\n"
            "1.  **í•µì‹¬ ì‚¬ê±´/ì£¼ì¥:** ì´ ê¸°ì‚¬ì˜ ê°€ì¥ ì¤‘ìš”í•œ ë©”ì‹œì§€ë‚˜ ì‚¬ê±´ì€ ë¬´ì—‡ì¸ê°€?\n"
            "2.  **êµ¬ì²´ì  ê·¼ê±° (ìˆ˜ì¹˜/ë°ì´í„°):** í•µì‹¬ ì£¼ì¥ì„ ë’·ë°›ì¹¨í•˜ëŠ” êµ¬ì²´ì ì¸ ìˆ«ì, ë¹„ìœ¨(%), ê¸ˆì•¡, ë‚ ì§œ ë“±ì´ ìˆë‹¤ë©´ **ì •í™•í•˜ê²Œ** ëª…ì‹œí•˜ë¼.\n"
            "3.  **ê´€ë ¨ ì£¼ì²´:** ì´ ì‚¬ê±´ì˜ í•µì‹¬ ì¸ë¬¼, íšŒì‚¬, ê¸°ê´€ì€ ëˆ„êµ¬ì¸ê°€?\n"
            "4.  **ì–¸ê¸‰ëœ ì˜í–¥/ì „ë§:** ì´ ì‚¬ê±´ì´ í•´ë‹¹ íšŒì‚¬, ì‚°ì—…, ë˜ëŠ” ì‹œì¥ì— ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ê¸ì •ì /ë¶€ì •ì  ì˜í–¥ì´ë‚˜ í–¥í›„ ì „ë§ì— ëŒ€í•œ ì–¸ê¸‰ì´ ìˆë‹¤ë©´ í¬í•¨í•˜ë¼.\n\n"
            "**ì¶œë ¥ ì§€ì¹¨:** ë¶ˆí•„ìš”í•œ ë¯¸ì‚¬ì—¬êµ¬ë‚˜ ì„œë¡ /ê²°ë¡ ì€ ìƒëµí•˜ê³  í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì „ë‹¬í•  ê²ƒ."
        )
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"[ERROR] ChatGPT ìš”ì•½ ì˜¤ë¥˜: {e}")
        return None

def summarize_korean_text_basic(text, num_sentences=5):
    """ê¸°ë³¸ ìš”ì•½ í•¨ìˆ˜"""
    sentences = re.split(r'(?<=[.?!])\s*', text)
    summary = ' '.join(sentences[:num_sentences])
    if summary and not summary[-1] in ('.', '?', '!'):
        return summary + '.'
    return summary

# ê¸°ì‚¬ ë¶„ì„ í•¨ìˆ˜ (ì›ë³¸ ë¡œì§)
PREFERRED_SOURCES = ['reuters', 'associated press', 'cnbc', 'forbes', 'business insider', 'korea']
NEWS_LIMIT = 10  # í…ŒìŠ¤íŠ¸ ë‹¨ê³„: 10ê°œë¡œ ì œí•œ

def source_score(site):
    """ì¶œì²˜ ì ìˆ˜ ê³„ì‚°"""
    if not site:
        return 0
    site = site.lower()
    for i, s in enumerate(PREFERRED_SOURCES[::-1]):
        if s in site:
            return (i + 1) * 10
    return 1

def length_score(text_len):
    """ê¸¸ì´ ì ìˆ˜ ê³„ì‚°"""
    if text_len > 3000:
        return 10
    elif text_len > 1500:
        return 7
    elif text_len > 700:
        return 4
    else:
        return 1

def find_and_process_high_scoring_articles(news_list, ticker_names):
    """ê³ ì ìˆ˜ ê¸°ì‚¬ ì°¾ê¸° ë° ì²˜ë¦¬ (ì›ë³¸ ë¡œì§)"""
    print(f"ì´ {len(news_list)}ê°œ ë‰´ìŠ¤ ì¤‘ ë² ìŠ¤íŠ¸ ê¸°ì‚¬ ì„ ë³„ ì¤‘...")
    HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
    }
    
    scored_articles = []
    for i, art in enumerate(news_list[:NEWS_LIMIT]):
        url = art.get("url")
        site = art.get("site", "")
        current_title = art.get("title", "")
        art_meta = art
        try:
            r = requests.get(url, headers=HEADERS, timeout=10)
            r.raise_for_status()
            article = Article(url)
            article.set_html(r.text)
            article.parse()
            article_text = article.text
            if len(article_text) < 200:
                continue
            rel_score = 0
            if current_title:
                current_title_lower = current_title.lower()
                for k in ticker_names:
                    if k.lower() in current_title_lower:
                        rel_score += 1
            score = (source_score(site) * 3 + length_score(len(article_text)) * 1.5 + rel_score * 2)
            scored_articles.append({'article_obj': article, 'meta': art, 'score': score})
            print(f"     [{i+1:02d}] {site:20s} | ì ìˆ˜: {score:4.1f} | ì œëª©: {current_title[:40]}...")
        except Exception as e:
            print(f"     [ERROR] {site} ê¸°ì‚¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    if not scored_articles:
        print("[WARN] ìœ íš¨í•œ ê¸°ì‚¬ ì—†ìŒ.")
        return []
    
    scored_articles.sort(key=lambda x: x['score'], reverse=True)
    processed_articles = []
    processed_titles_set = set()
    SCORE_THRESHOLD = 100
    SIMILARITY_THRESHOLD = 0.8
    
    print(f"\n--- {SCORE_THRESHOLD}ì  ì´ìƒ ê¸°ì‚¬ ì„ ë³„ ë° (1ì°¨)ì œëª© ì¤‘ë³µ ì œê±° ---")
    for article_data in scored_articles:
        score = article_data['score']
        art_meta = article_data['meta']
        article_obj = article_data['article_obj']
        proc_title = art_meta.get('title', '')
        if score < SCORE_THRESHOLD:
            continue
        is_duplicate = False
        for processed_title in processed_titles_set:
            similarity = difflib.SequenceMatcher(None, proc_title, processed_title).ratio()
            if similarity > SIMILARITY_THRESHOLD:
                is_duplicate = True
                print(f"     [1ì°¨ ì¤‘ë³µ ê°ì§€] (ì ìˆ˜: {score:.1f}) {proc_title[:50]}... (ìœ ì‚¬ë„: {similarity*100:.0f}%)")
                break
        if not is_duplicate:
            print(f"[OK] (ì ìˆ˜: {score:.1f}) ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘: {art_meta.get('site')} | {proc_title}")
            processed_titles_set.add(proc_title)
            text_ko = translate_text(article_obj.text)
            summary_ko = summarize_with_chatgpt(text_ko)
            if not summary_ko:
                summary_ko = summarize_korean_text_basic(text_ko)
            processed_articles.append({
                'date': pd.to_datetime(art_meta.get('publishedDate')).strftime('%Y-%m-%d %H:%M') if art_meta.get('publishedDate') else '',
                'site': art_meta.get('site'),
                'url': art_meta.get('url'),
                'title_ko': translate_text(article_obj.title),
                'summary_ko': summary_ko
            })
    
    # 100ì  ì´ìƒ ê¸°ì‚¬ê°€ ì—†ìœ¼ë©´ ì ìˆ˜ ìƒê´€ì—†ì´ ìƒìœ„ ê¸°ì‚¬ ë°˜í™˜ (í…ŒìŠ¤íŠ¸ ë‹¨ê³„)
    if not processed_articles:
        print("[WARN] 100ì  ì´ìƒì¸ ìœ íš¨í•œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ì ìˆ˜ ìƒê´€ì—†ì´ ìƒìœ„ ê¸°ì‚¬ ë°˜í™˜ ì¤‘...")
        processed_titles_set = set()
        for article_data in scored_articles[:5]:  # ìƒìœ„ 5ê°œë§Œ
            score = article_data['score']
            art_meta = article_data['meta']
            article_obj = article_data['article_obj']
            proc_title = art_meta.get('title', '')
            
            is_duplicate = False
            for processed_title in processed_titles_set:
                similarity = difflib.SequenceMatcher(None, proc_title, processed_title).ratio()
                if similarity > SIMILARITY_THRESHOLD:
                    is_duplicate = True
                    break
            if not is_duplicate:
                print(f"[OK] (ì ìˆ˜: {score:.1f}) ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘: {art_meta.get('site')} | {proc_title}")
                processed_titles_set.add(proc_title)
                text_ko = translate_text(article_obj.text)
                summary_ko = summarize_with_chatgpt(text_ko)
                if not summary_ko:
                    summary_ko = summarize_korean_text_basic(text_ko)
                processed_articles.append({
                    'date': pd.to_datetime(art_meta.get('publishedDate')).strftime('%Y-%m-%d %H:%M') if art_meta.get('publishedDate') else '',
                    'site': art_meta.get('site'),
                    'url': art_meta.get('url'),
                    'title_ko': translate_text(article_obj.title),
                    'summary_ko': summary_ko
                })
    
    return processed_articles

# ë‰´ìŠ¤ API ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/stock/<symbol>/news', methods=['GET'])
def get_stock_news_api(symbol):
    """ì£¼ì‹ ë‰´ìŠ¤ ì¡°íšŒ API"""
    try:
        # ì‹¬ë³¼ ì •ë¦¬
        clean_symbol = symbol.replace('.KS', '').replace('.KQ', '').upper()
        
        # í•œêµ­ ì£¼ì‹ì¸ ê²½ìš° ì‹¬ë³¼ ë³€í™˜ í•„ìš” ì—†ìŒ
        if len(clean_symbol) == 6 and clean_symbol.isdigit():
            # í•œêµ­ ì£¼ì‹ì€ FMPì—ì„œ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
            return jsonify({'news': []})
        
        # ChromaDBì—ì„œ ë¯¸ë¦¬ ì •ë¦¬ëœ ë‰´ìŠ¤ ìš°ì„  ì¡°íšŒ
        news_from_chroma = []
        try:
            news_from_chroma = fetch_us_stock_news(clean_symbol, limit=3)
        except Exception as chroma_error:
            print(f"[WARN] Chroma ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {chroma_error}")

        if news_from_chroma:
            print(f"[INFO] Chromaì—ì„œ {len(news_from_chroma)}ê°œ ë‰´ìŠ¤ ê°€ì ¸ì˜´ ({clean_symbol})")
            response_items = []
            for item in news_from_chroma:
                # ë‚ ì§œ í•„ë“œ: date > published_at > date_int ë³€í™˜
                date_str = item.get('date') or item.get('published_at') or ''
                if not date_str and item.get('date_int'):
                    # date_intë¥¼ ë‚ ì§œ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì˜ˆ: 20251024 -> 2025-10-24)
                    try:
                        date_int_str = str(item.get('date_int'))
                        if len(date_int_str) == 8:
                            date_str = f"{date_int_str[:4]}-{date_int_str[4:6]}-{date_int_str[6:8]}"
                    except:
                        pass
                
                response_items.append(
                    {
                        'title': item.get('title') or '',
                        'summary': item.get('summary') or '',
                        'url': item.get('url') or '',
                        'date': date_str,
                        'site': item.get('source') or item.get('site') or '',
                    }
                )
            print(f"[DEBUG] US news response items: {len(response_items)}ê°œ")
            return jsonify({'news': response_items})

        # í´ë°±: ê¸°ì¡´ FMP ë¡œì§
        print(f'\n--- [INFO] {clean_symbol} ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘ (FMP í´ë°±) ---')
        ticker_names = [clean_symbol]
        news_list = get_fmp_stock_news(clean_symbol, FMP_API_KEY, limit=NEWS_LIMIT)
        
        if not news_list:
            print(f"[WARN] {clean_symbol}ì— ëŒ€í•œ FMP ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return jsonify({'news': []})
        
        print(f"[INFO] FMPì—ì„œ {len(news_list)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        
        # 100ì  ì´ìƒ ê¸°ì‚¬ ì„ ë³„, ë²ˆì—­, ChatGPT ìš”ì•½ (ì—†ìœ¼ë©´ ì ìˆ˜ ìƒê´€ì—†ì´ ìƒìœ„ ê¸°ì‚¬ ë°˜í™˜)
        best_articles = find_and_process_high_scoring_articles(news_list, ticker_names)
        
        if not best_articles:
            print(f"[WARN] {clean_symbol}ì— ëŒ€í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (í•„í„°ë§ í›„ 0ê°œ)")
            # ì›ë³¸ ë‰´ìŠ¤ ì¤‘ ìƒìœ„ 5ê°œë¥¼ ê°„ë‹¨íˆ ë°˜í™˜ (ë²ˆì—­ ì—†ì´)
            print(f"[INFO] ì›ë³¸ ë‰´ìŠ¤ {min(5, len(news_list))}ê°œ ë°˜í™˜ ì‹œë„")
            processed_news = []
            for article in news_list[:5]:
                title = article.get('title', '')
                published_date = article.get('publishedDate', '')
                site = article.get('site', '')
                url = article.get('url', '')
                
                # ë‚ ì§œ í¬ë§·íŒ…
                date_str = ''
                if published_date:
                    try:
                        from datetime import datetime
                        dt = datetime.fromisoformat(published_date.replace('Z', '+00:00'))
                        date_str = dt.strftime('%Y-%m-%d %H:%M')
                    except:
                        date_str = published_date[:10] if len(published_date) >= 10 else published_date
                
                processed_news.append({
                    'title': title,
                    'summary': article.get('text', '')[:200] + '...' if article.get('text') else '',
                    'url': url,
                    'date': date_str,
                    'site': site or 'Unknown'
                })
            
            if processed_news:
                print(f"[OK] ì›ë³¸ ë‰´ìŠ¤ {len(processed_news)}ê°œ ë°˜í™˜")
                return jsonify({'news': processed_news})
            else:
                return jsonify({'news': []})
        
        # ìµœëŒ€ 10ê°œ ë°˜í™˜ (ê¸°ì¡´ 5ê°œì—ì„œ ì¦ê°€)
        processed_news = []
        for article in best_articles[:10]:
            processed_news.append({
                'title': article.get('title_ko', ''),
                'summary': article.get('summary_ko', ''),
                'url': article.get('url', ''),
                'date': article.get('date', ''),
                'site': article.get('site', '')
            })
        
        print(f"[OK] ì²˜ë¦¬ëœ ë‰´ìŠ¤ {len(processed_news)}ê°œ ë°˜í™˜")
        return jsonify({'news': processed_news})
    except Exception as e:
        print(f'ë‰´ìŠ¤ API ì˜¤ë¥˜: {e}')
        return jsonify({'news': []})

# í•œêµ­ ì£¼ì‹ ë‰´ìŠ¤ API ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/kr-stock/<symbol>/news', methods=['GET'])
def get_kr_stock_news(symbol):
    """í•œêµ­ ì£¼ì‹ ë‰´ìŠ¤ ì¡°íšŒ API (ChromaDB ìš°ì„ , ë„¤ì´ë²„ ë‰´ìŠ¤ í´ë°±, FMP í´ë°±)"""
    try:
        # ì‹¬ë³¼ ì •ë¦¬ (.KS ì œê±°)
        clean_symbol = symbol.replace('.KS', '').replace('.KQ', '')
        
        if not clean_symbol.isdigit() or len(clean_symbol) != 6:
            return jsonify({'error': 'ì˜¬ë°”ë¥¸ ì‹¬ë³¼ ì½”ë“œê°€ ì•„ë‹™ë‹ˆë‹¤.'}), 400
        
        # ChromaDBì—ì„œ ë¯¸ë¦¬ ì •ë¦¬ëœ ë‰´ìŠ¤ ìš°ì„  ì¡°íšŒ
        news_from_chroma = []
        try:
            news_from_chroma = fetch_kr_stock_news(clean_symbol, limit=10)
        except Exception as chroma_error:
            print(f"[WARN] Chroma ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨ (KR): {chroma_error}")
        
        if news_from_chroma:
            print(f"[INFO] Chromaì—ì„œ {len(news_from_chroma)}ê°œ ë‰´ìŠ¤ ê°€ì ¸ì˜´ (KR: {clean_symbol})")
            response_items = []
            for item in news_from_chroma:
                response_items.append(
                    {
                        'title': item.get('title') or '',
                        'summary': item.get('summary') or '',
                        'url': item.get('url') or '',
                        'date': item.get('date') or item.get('published_at') or '',
                        'site': item.get('source') or '',
                    }
                )
            return jsonify({'news': response_items})
        
        # íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì‚¬ìš©)
        krx_list = get_krx_list_cached()
        company_name = clean_symbol
        if krx_list is not None and not krx_list.empty:
            symbol_col = 'Code' if 'Code' in krx_list.columns else ('Symbol' if 'Symbol' in krx_list.columns else None)
            name_col = 'Name' if 'Name' in krx_list.columns else 'ì¢…ëª©ëª…'
            if symbol_col:
                company_info = krx_list[krx_list[symbol_col] == clean_symbol]
                if not company_info.empty:
                    company_name = company_info.iloc[0][name_col]
        
        # ë‰´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        news = []
        
        # 1. ë„¤ì´ë²„ ë‰´ìŠ¤ ìš°ì„  ì‹œë„
        if NAVER_CLIENT_ID and NAVER_CLIENT_SECRET:
            try:
                print(f'\n--- [INFO] {company_name} ({clean_symbol}) ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ ---')
                # ì •í™•ë„ ìš°ì„ 
                naver_news = collect_naver_news(company_name, sort="sim")
                
                # ë¶€ì¡±í•˜ë©´ ìµœì‹ ìˆœ ë³´ì¶©
                if len(naver_news) < NAVER_NEWS_TARGET_COUNT:
                    print(f'[INFO] ë„¤ì´ë²„ ë‰´ìŠ¤ {len(naver_news)}ê°œ ì°¾ìŒ, ìµœì‹ ìˆœ ë³´ì¶© ì¤‘...')
                    extra_news = collect_naver_news(company_name, sort="date")
                    existed_urls = set(n['url'] for n in naver_news)
                    for n in extra_news:
                        if n['url'] not in existed_urls:
                            naver_news.append(n)
                        if len(naver_news) >= NAVER_NEWS_TARGET_COUNT:
                            break
                
                if naver_news:
                    news = naver_news[:NAVER_NEWS_TARGET_COUNT]
                    print(f'[OK] ë„¤ì´ë²„ ë‰´ìŠ¤ {len(news)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ')
                else:
                    print(f'[WARN] ë„¤ì´ë²„ ë‰´ìŠ¤ 0ê°œ ìˆ˜ì§‘ë¨')
            except Exception as e:
                print(f'[ERROR] ë„¤ì´ë²„ ë‰´ìŠ¤ ì¡°íšŒ ì˜¤ë¥˜: {e}')
                import traceback
                traceback.print_exc()
        else:
            print(f'[WARN] ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ (CLIENT_ID: {bool(NAVER_CLIENT_ID)}, CLIENT_SECRET: {bool(NAVER_CLIENT_SECRET)})')
        
        # 2. ë„¤ì´ë²„ ë‰´ìŠ¤ê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•˜ë©´ FMP ë‰´ìŠ¤ë¡œ ë³´ì¶©
        if len(news) < 5:
            try:
                print(f'\n--- [INFO] {company_name} ({clean_symbol}) FMP ë‰´ìŠ¤ ë³´ì¶© ì‹œë„ ---')
                ticker_names = [company_name, clean_symbol]
                # í•œêµ­ ì£¼ì‹ì€ .KSë¥¼ ë¶™ì—¬ì„œ FMPì— ìš”ì²­
                kr_symbol_fmp = f"{clean_symbol}.KS"
                news_list = get_fmp_stock_news(kr_symbol_fmp, FMP_API_KEY, limit=NEWS_LIMIT)
                
                if news_list:
                    print(f'[INFO] FMPì—ì„œ {len(news_list)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘')
                    best_articles = find_and_process_high_scoring_articles(news_list, ticker_names)
                    
                    if best_articles:
                        print(f'[INFO] FMP ë‰´ìŠ¤ í•„í„°ë§ í›„ {len(best_articles)}ê°œ ê¸°ì‚¬')
                        existed_urls = set(n.get('url', '') for n in news)
                        for article in best_articles:
                            article_url = article.get('url', '')
                            if article_url and article_url not in existed_urls:
                                news.append({
                                    'title': article.get('title_ko', ''),
                                    'summary': article.get('summary_ko', ''),
                                    'url': article_url,
                                    'date': article.get('date', ''),
                                    'site': article.get('site', '')
                                })
                            if len(news) >= 10:
                                break
                    else:
                        print(f'[WARN] FMP ë‰´ìŠ¤ í•„í„°ë§ í›„ 0ê°œ ê¸°ì‚¬')
                else:
                    print(f'[WARN] FMP ë‰´ìŠ¤ ì—†ìŒ')
            except Exception as e:
                print(f'[ERROR] FMP ë‰´ìŠ¤ ì¡°íšŒ ì˜¤ë¥˜: {e}')
                import traceback
                traceback.print_exc()
        
        print(f'[INFO] ìµœì¢… ë‰´ìŠ¤ ê°œìˆ˜: {len(news)}ê°œ')
        return jsonify({'news': news[:10]})  # ìµœëŒ€ 10ê°œ ë°˜í™˜
    except Exception as e:
        print(f'[ERROR] í•œêµ­ ì£¼ì‹ ë‰´ìŠ¤ API ì˜¤ë¥˜: {e}')
        import traceback
        traceback.print_exc()
        return jsonify({'news': []})

# ============ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ìœ í‹¸ í•¨ìˆ˜ ============
def extract_segment_revenue_recursively(
    data: Union[Dict, List],
    min_revenue_threshold: int = 1_000_000,
    segment_data: Optional[Dict[str, int]] = None
) -> Dict[str, int]:
    """ì¬ê·€ì ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¶œ ë°ì´í„° ì¶”ì¶œ"""
    if segment_data is None:
        segment_data = {}
    if isinstance(data, dict):
        for key, value in data.items():
            lower_key = str(key).lower()
            # ë‚ ì§œ/ë©”íƒ€ í•„ë“œ ìŠ¤í‚µ
            if any(sub in lower_key for sub in [
                'date','year','id','total','sum','all','percentage','share','ratio',
                'filingdate','fillingdate','revenue_amount','asofdate','reported'
            ]):
                if isinstance(value, (dict, list)):
                    extract_segment_revenue_recursively(value, min_revenue_threshold, segment_data)
                continue
            if isinstance(value, (int, float)) and isinstance(key, str):
                if abs(value) >= min_revenue_threshold:
                    segment_data[key] = int(value)
            elif isinstance(value, (dict, list)):
                extract_segment_revenue_recursively(value, min_revenue_threshold, segment_data)
    elif isinstance(data, list):
        for item in data:
            extract_segment_revenue_recursively(item, min_revenue_threshold, segment_data)
    return segment_data

def normalize_segment_data(raw: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], Optional[str]]:
    """ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì •ê·œí™”"""
    latest_date = None
    # ë‚ ì§œ ì¶”ì¶œ ì‹œë„
    for it in raw:
        if isinstance(it, dict):
            date_keys = ['date', 'fillingDate', 'filingDate', 'asOfDate', 'reportedDate', 'calendarYear']
            for dk in date_keys:
                if dk in it:
                    try:
                        dt = pd.to_datetime(it[dk], errors="coerce")
                        if pd.notna(dt):
                            if latest_date is None or dt > pd.to_datetime(latest_date):
                                latest_date = str(dt.date())
                    except:
                        pass
    
    has_rows = [it for it in raw if isinstance(it, dict)]
    count_struct = sum(1 for it in has_rows if ('category' in it or 'segment' in it) and ('revenue' in it))
    
    # êµ¬ì¡°í™”ëœ ë°ì´í„° (category/segment í•„ë“œ ìˆìŒ)
    if count_struct >= max(1, len(has_rows)//4):
        rows = []
        for it in has_rows:
            cat = it.get("category") or it.get("segment") or it.get("name") or it.get("type")
            rev = it.get("revenue")
            if cat is None or rev is None:
                continue
            try:
                rev = float(rev)
            except:
                continue
            rows.append({'segment': str(cat), 'revenue': rev})
        
        if rows:
            # ê·¸ë£¹í™” ë° í•©ê³„
            df = pd.DataFrame(rows)
            df = df.groupby("segment", as_index=False)["revenue"].sum()
            total = df["revenue"].sum()
            if total <= 0:
                return [], latest_date
            df["percentage"] = df["revenue"] / total * 100.0
            df = df.sort_values("revenue", ascending=False).reset_index(drop=True)
            return df.to_dict('records'), latest_date
    
    # ë¹„êµ¬ì¡°í™”ëœ ë°ì´í„° (ì¬ê·€ ì¶”ì¶œ)
    seg_map = extract_segment_revenue_recursively(raw, min_revenue_threshold=1_000_000)
    if not seg_map:
        return [], latest_date
    
    df = pd.DataFrame(list(seg_map.items()), columns=["segment", "revenue"])
    df["revenue"] = pd.to_numeric(df["revenue"], errors="coerce").fillna(0)
    df = df[df["revenue"] > 0]
    total = df["revenue"].sum()
    if total <= 0:
        return [], latest_date
    df["percentage"] = df["revenue"] / total * 100.0
    df = df.sort_values("revenue", ascending=False).reset_index(drop=True)
    return df.to_dict('records'), latest_date

def get_reported_currency(ticker: str) -> str:
    """ë³´ê³  í†µí™” ê°€ì ¸ì˜¤ê¸°"""
    try:
        url = f"https://financialmodelingprep.com/api/v3/income-statement/{ticker}"
        params = {"period": "quarter", "limit": 1, "apikey": FMP_API_KEY}
        response = requests.get(url, params=params, timeout=5)
        if response.status_code == 200:
            data = response.json()
            if data and isinstance(data, list) and len(data) > 0:
                cur = data[0].get("reportedCurrency") or data[0].get("currency")
                if cur:
                    return cur.upper()
    except:
        pass
    return "USD"

def fetch_segment_data(ticker: str) -> Optional[Dict[str, Any]]:
    """ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì§§ê²Œ)"""
    try:
        url = "https://financialmodelingprep.com/api/v4/revenue-product-segmentation"
        params = {"symbol": ticker, "period": "quarter", "apikey": FMP_API_KEY}
        print(f'[INFO] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ìš”ì²­: {ticker}')
        response = requests.get(url, params=params, timeout=5)  # íƒ€ì„ì•„ì›ƒ 5ì´ˆë¡œ ì¦ê°€
        
        if response.status_code != 200:
            print(f'[ERROR] ì„¸ê·¸ë¨¼íŠ¸ API ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}')
            return None
        
        data = response.json()
        if not data:
            print(f'[WARN] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ: {ticker}')
            return None
        
        print(f'[INFO] ì„¸ê·¸ë¨¼íŠ¸ ì›ë³¸ ë°ì´í„° ìˆ˜: {len(data) if isinstance(data, list) else "dict"}')
        segments, date_str = normalize_segment_data(data)
        
        if not segments:
            print(f'[WARN] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì •ê·œí™” ì‹¤íŒ¨: {ticker}')
            return None
        
        print(f'[OK] ì„¸ê·¸ë¨¼íŠ¸ ì •ê·œí™” ì„±ê³µ: {len(segments)}ê°œ')
        currency = get_reported_currency(ticker)
        
        return {
            'segments': segments,
            'date': date_str,
            'currency': currency
        }
    except requests.exceptions.Timeout:
        print(f'[TIMEOUT] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ íƒ€ì„ì•„ì›ƒ: {ticker}')
        return None
    except Exception as e:
        print(f'[ERROR] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {ticker} - {type(e).__name__}: {str(e)}')
        import traceback
        traceback.print_exc()
        return None

# ì¬ë¬´ì œí‘œ API ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/stock/<symbol>/financials', methods=['GET'])
def get_stock_financials(symbol):
    """ì£¼ì‹ ì¬ë¬´ì œí‘œ ì¡°íšŒ API"""
    try:
        # ì‹¬ë³¼ ì •ë¦¬
        clean_symbol = symbol.replace('.KS', '').replace('.KQ', '').upper()
        
        # í•œêµ­ ì£¼ì‹ì¸ ê²½ìš° - DART API ì‚¬ìš©
        if len(clean_symbol) == 6 and clean_symbol.isdigit():
            # DART APIë¡œ ì¬ë¬´ì œí‘œ ê°€ì ¸ì˜¤ê¸°
            if DART_API_KEY:
                try:
                    corp_code = find_dart_corp_code(clean_symbol)
                    if corp_code:
                        financials = get_dart_financials(corp_code, clean_symbol)
                        if financials:
                            return jsonify(financials)
                except Exception as e:
                    print(f'DART API ì¬ë¬´ì œí‘œ ì¡°íšŒ ì˜¤ë¥˜: {e}')
            
            # DART ì‹¤íŒ¨ ì‹œ FMP APIë¡œ í´ë°±
            try:
                kr_symbol = f"{clean_symbol}.KS"
                url = f"https://financialmodelingprep.com/api/v3/income-statement/{kr_symbol}?period=quarter&limit=4&apikey={FMP_API_KEY}"
                response = requests.get(url, timeout=10)
                response.raise_for_status()
                income_statements = response.json()
                
                if isinstance(income_statements, dict) and 'Error Message' in income_statements:
                    raise Exception("FMP APIì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                if not income_statements or len(income_statements) == 0:
                    return jsonify({
                        'revenue': [],
                        'netIncome': [],
                        'operatingIncome': [],
                        'chartData': []
                    })
                
                # FMP ë°ì´í„° íŒŒì‹±
                chart_data = []
                revenue_data = []
                net_income_data = []
                operating_income_data = []
                
                for statement in reversed(income_statements):
                    year = statement.get('calendarYear', '')
                    quarter = statement.get('quarter', '')
                    revenue = statement.get('revenue', 0) or 0
                    net_income = statement.get('netIncome', 0) or 0
                    operating_income = statement.get('operatingIncome', 0) or 0
                    
                    if year and quarter:
                        label = f"{year} Q{quarter}"
                    else:
                        label = year if year else ''
                    
                    if label:
                        chart_data.append({
                            'year': label,
                            'revenue': revenue,
                            'netIncome': net_income,
                            'operatingIncome': operating_income
                        })
                        revenue_data.append({'year': label, 'value': revenue})
                        net_income_data.append({'year': label, 'value': net_income})
                        operating_income_data.append({'year': label, 'value': operating_income})
                
                latest = income_statements[0] if income_statements else {}
                latest_year = latest.get('calendarYear', '')
                latest_quarter = latest.get('quarter', '')
                latest_label = f"{latest_year} Q{latest_quarter}" if latest_year and latest_quarter else latest_year
                
                # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ë³‘ë ¬ë¡œ ê°€ì ¸ì˜¤ê¸° (ì„ íƒì , ì‹¤íŒ¨í•´ë„ ë¬´ë°©)
                segment_data = None
                try:
                    with ThreadPoolExecutor(max_workers=1) as executor:
                        future = executor.submit(fetch_segment_data, kr_symbol)
                        try:
                            segment_data = future.result(timeout=5)  # íƒ€ì„ì•„ì›ƒ 5ì´ˆë¡œ ì¦ê°€
                            if segment_data:
                                print(f'[OK] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ: {kr_symbol} ({len(segment_data.get("segments", []))}ê°œ ì„¸ê·¸ë¨¼íŠ¸)')
                            else:
                                print(f'[WARN] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì—†ìŒ: {kr_symbol}')
                        except Exception as e:
                            print(f'[WARN] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {kr_symbol} - {str(e)}')
                except Exception as e:
                    print(f'[WARN] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {kr_symbol} - {str(e)}')
                
                result = {
                    'revenue': revenue_data,
                    'netIncome': net_income_data,
                    'operatingIncome': operating_income_data,
                    'chartData': chart_data,
                    'latest': {
                        'revenue': latest.get('revenue', 0) or 0,
                        'netIncome': latest.get('netIncome', 0) or 0,
                        'operatingIncome': latest.get('operatingIncome', 0) or 0,
                        'year': latest_label
                    }
                }
                
                # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if segment_data:
                    result['segments'] = segment_data['segments']
                    result['segmentDate'] = segment_data['date']
                    result['segmentCurrency'] = segment_data['currency']
                
                return jsonify(result)
            except Exception as e:
                print(f'FMP í´ë°± ì˜¤ë¥˜: {e}')
                return jsonify({
                    'revenue': [],
                    'netIncome': [],
                    'operatingIncome': [],
                    'chartData': []
                })
        
        # í•´ì™¸ ì£¼ì‹ ì¬ë¬´ì œí‘œ ê°€ì ¸ì˜¤ê¸° (FMP API)
        try:
            chroma_financials = fetch_us_financials_from_chroma(clean_symbol)
            if chroma_financials:
                print(f'[INFO] ChromaDB ì¬ë¬´ ë°ì´í„° ì‚¬ìš©: {clean_symbol}')
                return jsonify(chroma_financials)
        except Exception as e:
            print(f'[WARN] ChromaDB ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {clean_symbol} - {e}')

        try:
            # ë¶„ê¸°ë³„ ì¬ë¬´ì œí‘œ ë°ì´í„°
            url = f"https://financialmodelingprep.com/api/v3/income-statement/{clean_symbol}?period=quarter&limit=4&apikey={FMP_API_KEY}"
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            income_statements = response.json()
            
            if not income_statements or len(income_statements) == 0:
                return jsonify({
                    'revenue': [],
                    'netIncome': [],
                    'operatingIncome': [],
                    'chartData': []
                })
            
            # ë°ì´í„° ì •ë¦¬ ë° ì°¨íŠ¸ìš© ë°ì´í„° ìƒì„±
            chart_data = []
            revenue_data = []
            net_income_data = []
            operating_income_data = []
            
            for statement in reversed(income_statements):  # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
                # ë¶„ê¸°ë³„ ë°ì´í„° ì²˜ë¦¬
                year = statement.get('calendarYear', '')
                period = statement.get('period', '')
                quarter = statement.get('quarter', '')
                revenue = statement.get('revenue', 0) or 0
                net_income = statement.get('netIncome', 0) or 0
                operating_income = statement.get('operatingIncome', 0) or 0
                
                # ë¶„ê¸° ë ˆì´ë¸” ìƒì„± (ì˜ˆ: 2024 Q1)
                if year and quarter:
                    label = f"{year} Q{quarter}"
                elif year and period:
                    label = f"{year} {period}"
                else:
                    label = year if year else ''
                
                if label:
                    chart_data.append({
                        'year': label,
                        'revenue': revenue,
                        'netIncome': net_income,
                        'operatingIncome': operating_income
                    })
                    revenue_data.append({'year': label, 'value': revenue})
                    net_income_data.append({'year': label, 'value': net_income})
                    operating_income_data.append({'year': label, 'value': operating_income})
            
            # ìµœì‹  ë°ì´í„°
            latest = income_statements[0] if income_statements else {}
            
            # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ë³‘ë ¬ë¡œ ê°€ì ¸ì˜¤ê¸° (ì„ íƒì , ì‹¤íŒ¨í•´ë„ ë¬´ë°©)
            segment_data = None
            try:
                with ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(fetch_segment_data, clean_symbol)
                    try:
                        segment_data = future.result(timeout=5)  # íƒ€ì„ì•„ì›ƒ 5ì´ˆë¡œ ì¦ê°€
                        if segment_data:
                            print(f'[OK] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ: {clean_symbol} ({len(segment_data.get("segments", []))}ê°œ ì„¸ê·¸ë¨¼íŠ¸)')
                        else:
                            print(f'[WARN] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì—†ìŒ: {clean_symbol}')
                    except Exception as e:
                        print(f'[WARN] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {clean_symbol} - {str(e)}')
            except Exception as e:
                print(f'[WARN] ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {clean_symbol} - {str(e)}')
            
            result = {
                'revenue': revenue_data,
                'netIncome': net_income_data,
                'operatingIncome': operating_income_data,
                'chartData': chart_data,
                'latest': {
                    'revenue': latest.get('revenue', 0) or 0,
                    'netIncome': latest.get('netIncome', 0) or 0,
                    'operatingIncome': latest.get('operatingIncome', 0) or 0,
                    'year': latest.get('calendarYear', '')
                }
            }
            
            # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if segment_data:
                result['segments'] = segment_data['segments']
                result['segmentDate'] = segment_data['date']
                result['segmentCurrency'] = segment_data['currency']
            
            return jsonify(result)
        except Exception as e:
            print(f'FMP ì¬ë¬´ì œí‘œ API ì˜¤ë¥˜: {e}')
            return jsonify({
                'revenue': [],
                'netIncome': [],
                'operatingIncome': [],
                'chartData': []
            })
    except Exception as e:
        print(f'ì¬ë¬´ì œí‘œ API ì˜¤ë¥˜: {e}')
        return jsonify({
            'revenue': [],
            'netIncome': [],
            'operatingIncome': [],
            'chartData': []
        })

# DART API ë‹¨ì¼ ì¡°íšŒ í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
def fetch_dart_quarter_data(corp_code, year, reprt_code, quarter, fs_div):
    """ë‹¨ì¼ ë¶„ê¸°/íƒ€ì…ì˜ DART ì¬ë¬´ì œí‘œ ë°ì´í„° ì¡°íšŒ"""
    url = "https://opendart.fss.or.kr/api/fnlttSinglAcnt.json"
    
    try:
        params = {
            'crtfc_key': DART_API_KEY,
            'corp_code': corp_code,
            'bsns_year': str(year),
            'reprt_code': reprt_code,
            'fs_div': fs_div
        }
        
        response = requests.get(url, params=params, timeout=15)
        response.raise_for_status()
        data = response.json()
        
        status = data.get('status')
        if status != '000':
            return None
        
        account_list = data.get('list', [])
        if not account_list:
            return None
        
        revenue = 0
        operating_income = 0
        net_income = 0
        
        # ëª¨ë“  ê³„ì •ì—ì„œ ë§¤ì¶œì•¡, ì˜ì—…ì´ìµ, ë‹¹ê¸°ìˆœì´ìµ ì°¾ê¸°
        for account in account_list:
            account_nm = account.get('account_nm', '')
            account_id = account.get('account_id', '')
            thstrm_amount = account.get('thstrm_amount', '0')
            
            try:
                amount_str = thstrm_amount.replace(',', '') if thstrm_amount else '0'
                amount = float(amount_str) if amount_str else 0
            except:
                amount = 0
            
            if amount == 0:
                continue
            
            # ë§¤ì¶œì•¡ ì°¾ê¸°
            if ('ë§¤ì¶œì•¡' in account_nm or 'ë§¤ì¶œ' in account_nm) and 'ê°ê°€ìƒê°ë¹„' not in account_nm:
                if abs(amount) > abs(revenue) or revenue == 0:
                    revenue = amount
            
            # ì˜ì—…ì´ìµ ì°¾ê¸°
            elif 'ì˜ì—…ì´ìµ' in account_nm or account_id == 'ifrs-full_OperatingIncomeLoss':
                if abs(amount) > abs(operating_income) or operating_income == 0:
                    operating_income = amount
            
            # ë‹¹ê¸°ìˆœì´ìµ ì°¾ê¸°
            elif ('ë‹¹ê¸°ìˆœì´ìµ' in account_nm or 'ìˆœì´ìµ' in account_nm) and 'ì¢…ì†ê¸°ì—…' not in account_nm:
                if abs(amount) > abs(net_income) or net_income == 0:
                    net_income = amount
        
        if revenue != 0 or operating_income != 0 or net_income != 0:
            return {
                'year': year,
                'quarter': quarter,
                'reprt_code': reprt_code,
                'fs_div': fs_div,
                'revenue': revenue,
                'operating_income': operating_income,
                'net_income': net_income
            }
        
        return None
    except Exception as e:
        return None

# DART Open APIë¡œ í•œêµ­ ì£¼ì‹ ì¬ë¬´ì œí‘œ ê°€ì ¸ì˜¤ê¸° (ë³‘ë ¬ ì²˜ë¦¬)
def get_dart_financials(corp_code, symbol):
    """DART Open APIë¡œ ì¬ë¬´ì œí‘œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ë³‘ë ¬ ì²˜ë¦¬)"""
    if not DART_API_KEY:
        return None
    
    try:
        current_year = datetime.now().year
        
        # ìµœê·¼ 4ë¶„ê¸° ì¬ë¬´ì œí‘œ ì¡°íšŒ
        chart_data = []
        revenue_data = []
        net_income_data = []
        operating_income_data = []
        
        # ë¶„ê¸° ì½”ë“œ ë§¤í•‘: 1ë¶„ê¸°(11013), ë°˜ê¸°(11012), 3ë¶„ê¸°(11014), ì‚¬ì—…ë³´ê³ ì„œ(11011)
        reprt_codes = [
            ('11013', 1),  # 1ë¶„ê¸°
            ('11012', 2),  # ë°˜ê¸°
            ('11014', 3),  # 3ë¶„ê¸°
            ('11011', 4)   # ì‚¬ì—…ë³´ê³ ì„œ
        ]
        
        # ìµœì‹  ë¶„ê¸°ë¶€í„° ìš°ì„ ìˆœìœ„ë¡œ ì‘ì—… ì¤€ë¹„ (CFS ìš°ì„ , ì—†ìœ¼ë©´ OFS)
        # ìµœì‹  ì—°ë„ë¶€í„°, ìµœì‹  ë¶„ê¸°ë¶€í„° ì—­ìˆœìœ¼ë¡œ
        tasks_priority = []
        for year_offset in range(2):
            year = current_year - year_offset
            # ìµœì‹  ë¶„ê¸°ë¶€í„° ì—­ìˆœ (Q4 â†’ Q3 â†’ Q2 â†’ Q1)
            for reprt_code, quarter in reversed(reprt_codes):
                # CFS ìš°ì„ 
                tasks_priority.append((year, reprt_code, quarter, 'CFS', True))  # True = ìš°ì„ ìˆœìœ„
        
        print(f'ë¹ ë¥¸ ì¡°íšŒ ì‹œì‘: ìµœì‹  ë¶„ê¸°ë¶€í„° ìš°ì„ ìˆœìœ„ ì¡°íšŒ (CFS ìš°ì„ )')
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì¡°íšŒ ì‹¤í–‰
        collected_data = {}  # (year, quarter)ë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ì œê±°
        
        with ThreadPoolExecutor(max_workers=8) as executor:
            # ìš°ì„ ìˆœìœ„ ì‘ì—…ë¶€í„° ì œì¶œ (CFSë§Œ ë¨¼ì €)
            futures_cfs = {}
            for year, reprt_code, quarter, fs_div, _ in tasks_priority:
                future = executor.submit(fetch_dart_quarter_data, corp_code, year, reprt_code, quarter, fs_div)
                futures_cfs[future] = (year, quarter, fs_div)
            
            # CFS ê²°ê³¼ ì²˜ë¦¬
            for future in as_completed(futures_cfs):
                year, quarter, fs_div = futures_cfs[future]
                try:
                    result = future.result()
                    if result:
                        key = (result['year'], result['quarter'])
                        collected_data[key] = result
                        print(f'ë°ì´í„° ì¶”ì¶œ: {result["year"]} Q{result["quarter"]} ({result["fs_div"]}) - ë§¤ì¶œì•¡: {result["revenue"]:,.0f}, ì˜ì—…ì´ìµ: {result["operating_income"]:,.0f}, ë‹¹ê¸°ìˆœì´ìµ: {result["net_income"]:,.0f}')
                        
                        # 4ê°œ ë¶„ê¸° ìˆ˜ì§‘ë˜ë©´ ì¦‰ì‹œ ì¤‘ë‹¨
                        if len(collected_data) >= 4:
                            # ë‚¨ì€ CFS ì‘ì—… ì·¨ì†Œ
                            for f in futures_cfs:
                                if not f.done():
                                    f.cancel()
                            break
                except Exception as e:
                    continue
            
            # CFSì—ì„œ 4ê°œë¥¼ ëª» ì°¾ì•˜ìœ¼ë©´ OFSë¡œ ë³´ì™„
            if len(collected_data) < 4:
                missing_quarters = []
                for year_offset in range(2):
                    year = current_year - year_offset
                    for reprt_code, quarter in reversed(reprt_codes):
                        key = (year, quarter)
                        if key not in collected_data:
                            missing_quarters.append((year, reprt_code, quarter))
                
                if missing_quarters:
                    print(f'CFSì—ì„œ {len(collected_data)}ê°œ ì°¾ìŒ, OFSë¡œ ë³´ì™„ ì‹œë„ ì¤‘...')
                    futures_ofs = {}
                    for year, reprt_code, quarter in missing_quarters[:8]:  # ìµœëŒ€ 8ê°œë§Œ
                        future = executor.submit(fetch_dart_quarter_data, corp_code, year, reprt_code, quarter, 'OFS')
                        futures_ofs[future] = (year, quarter, 'OFS')
                    
                    for future in as_completed(futures_ofs):
                        year, quarter, fs_div = futures_ofs[future]
                        try:
                            result = future.result()
                            if result:
                                key = (result['year'], result['quarter'])
                                if key not in collected_data:  # CFSì— ì—†ëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                                    collected_data[key] = result
                                    print(f'ë°ì´í„° ì¶”ì¶œ (OFS): {result["year"]} Q{result["quarter"]} - ë§¤ì¶œì•¡: {result["revenue"]:,.0f}, ì˜ì—…ì´ìµ: {result["operating_income"]:,.0f}, ë‹¹ê¸°ìˆœì´ìµ: {result["net_income"]:,.0f}')
                                    
                                    if len(collected_data) >= 4:
                                        for f in futures_ofs:
                                            if not f.done():
                                                f.cancel()
                                        break
                        except Exception as e:
                            continue
        
        # ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_data = sorted(collected_data.values(), key=lambda x: (x['year'], x['quarter']), reverse=True)[:4]
        
        for data in sorted_data:
            label = f"{data['year']} Q{data['quarter']}"
            chart_data.append({
                'year': label,
                'revenue': data['revenue'],
                'netIncome': data['net_income'],
                'operatingIncome': data['operating_income']
            })
            revenue_data.append({'year': label, 'value': data['revenue']})
            net_income_data.append({'year': label, 'value': data['net_income']})
            operating_income_data.append({'year': label, 'value': data['operating_income']})
        
        if not chart_data:
            print(f'DARTì—ì„œ ì¬ë¬´ì œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {symbol}')
            return None
        
        # ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ (ì´ë¯¸ reverse=Trueë¡œ ì •ë ¬í–ˆìœ¼ë¯€ë¡œ ë‹¤ì‹œ reverse)
        chart_data.reverse()
        revenue_data.reverse()
        net_income_data.reverse()
        operating_income_data.reverse()
        
        # ìµœì‹  ë°ì´í„°
        latest = chart_data[-1] if chart_data else {}
        
        return {
            'revenue': revenue_data,
            'netIncome': net_income_data,
            'operatingIncome': operating_income_data,
            'chartData': chart_data,
            'latest': {
                'revenue': latest.get('revenue', 0) or 0,
                'netIncome': latest.get('netIncome', 0) or 0,
                'operatingIncome': latest.get('operatingIncome', 0) or 0,
                'year': latest.get('year', '')
            }
        }
    except Exception as e:
        print(f'DART API ì˜¤ë¥˜: {e}')
        import traceback
        traceback.print_exc()
        return None

# DART íšŒì‚¬ì½”ë“œ ZIP íŒŒì¼ ìºì‹œ ê²½ë¡œ
# ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì • (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
CACHE_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'cache')
# ìºì‹œ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
if not os.path.exists(CACHE_DIR):
    os.makedirs(CACHE_DIR, exist_ok=True)
    print(f'ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±: {CACHE_DIR}')

DART_CORPCODE_CACHE_FILE = os.path.join(CACHE_DIR, 'dart_corpcode_cache.zip')
DART_CORPCODE_CACHE_AGE_DAYS = 7  # 7ì¼ë§ˆë‹¤ ê°±ì‹ 

# KRX ë¦¬ìŠ¤íŠ¸ ìºì‹œ (ì „ì—­ ë³€ìˆ˜)
KRX_LIST_CACHE = None
KRX_LIST_CACHE_TIME = None
KRX_LIST_CACHE_AGE_SECONDS = 3600  # 1ì‹œê°„ë§ˆë‹¤ ê°±ì‹ 

def get_krx_list_cached():
    """KRX ë¦¬ìŠ¤íŠ¸ë¥¼ ìºì‹œí•˜ì—¬ ë¹ ë¥´ê²Œ ë°˜í™˜"""
    global KRX_LIST_CACHE, KRX_LIST_CACHE_TIME
    from datetime import datetime, timedelta
    
    # ìºì‹œê°€ ìˆê³  ìœ íš¨í•˜ë©´ ë°˜í™˜
    if KRX_LIST_CACHE is not None and KRX_LIST_CACHE_TIME is not None:
        cache_age = (datetime.now() - KRX_LIST_CACHE_TIME).total_seconds()
        if cache_age < KRX_LIST_CACHE_AGE_SECONDS:
            print(f'KRX ë¦¬ìŠ¤íŠ¸ ìºì‹œ ì‚¬ìš© (ìºì‹œ ë‚˜ì´: {cache_age:.0f}ì´ˆ)')
            return KRX_LIST_CACHE
    
    # ìºì‹œê°€ ì—†ê±°ë‚˜ ì˜¤ë˜ë˜ì—ˆìœ¼ë©´ ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ
    print('KRX ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘...')
    try:
        KRX_LIST_CACHE = fdr.StockListing('KRX')
        KRX_LIST_CACHE_TIME = datetime.now()
        print(f'KRX ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(KRX_LIST_CACHE) if KRX_LIST_CACHE is not None else 0}ê°œ ì¢…ëª©')
        return KRX_LIST_CACHE
    except Exception as e:
        print(f'KRX ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}')
        return None

def download_dart_corpcode_file():
    """DART íšŒì‚¬ì½”ë“œ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥"""
    if not DART_API_KEY:
        return None
    
    try:
        url = "https://opendart.fss.or.kr/api/corpCode.xml"
        params = {
            'crtfc_key': DART_API_KEY
        }
        
        print('DART íšŒì‚¬ì½”ë“œ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...')
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        # ZIP íŒŒì¼ ì €ì¥
        with open(DART_CORPCODE_CACHE_FILE, 'wb') as f:
            f.write(response.content)
        
        print(f'DART íšŒì‚¬ì½”ë“œ ZIP íŒŒì¼ ì €ì¥ ì™„ë£Œ: {DART_CORPCODE_CACHE_FILE}')
        return response.content
    except Exception as e:
        print(f'DART íšŒì‚¬ì½”ë“œ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}')
        return None

def load_dart_corpcode_from_cache():
    """ì €ì¥ëœ ZIP íŒŒì¼ì—ì„œ íšŒì‚¬ì½”ë“œ ëª©ë¡ ë¡œë“œ"""
    import os
    import zipfile
    import io
    from datetime import datetime, timedelta
    
    # ìºì‹œ íŒŒì¼ì´ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ
    if not os.path.exists(DART_CORPCODE_CACHE_FILE):
        print('ìºì‹œ íŒŒì¼ ì—†ìŒ, ë‹¤ìš´ë¡œë“œ ì‹œì‘...')
        download_dart_corpcode_file()
    
    # ìºì‹œ íŒŒì¼ì´ ë„ˆë¬´ ì˜¤ë˜ë˜ì—ˆìœ¼ë©´ ê°±ì‹ 
    if os.path.exists(DART_CORPCODE_CACHE_FILE):
        file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(DART_CORPCODE_CACHE_FILE))
        if file_age.days > DART_CORPCODE_CACHE_AGE_DAYS:
            print(f'ìºì‹œ íŒŒì¼ì´ {file_age.days}ì¼ ê²½ê³¼, ê°±ì‹  ì¤‘...')
            download_dart_corpcode_file()
    
    # ì €ì¥ëœ ZIP íŒŒì¼ ì½ê¸°
    try:
        with open(DART_CORPCODE_CACHE_FILE, 'rb') as f:
            zip_content = f.read()
        
        zip_file = zipfile.ZipFile(io.BytesIO(zip_content))
        xml_files = [f for f in zip_file.namelist() if f.endswith('.xml')]
        if not xml_files:
            print('ZIP íŒŒì¼ì— XML íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
            return None
        
        xml_content = zip_file.read(xml_files[0])
        # ì¸ì½”ë”© ì²˜ë¦¬
        try:
            xml_text = xml_content.decode('utf-8')
        except:
            xml_text = xml_content.decode('euc-kr')
        
        import xml.etree.ElementTree as ET
        root = ET.fromstring(xml_text)
        return root
    except Exception as e:
        print(f'ìºì‹œ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}')
        # ìºì‹œ íŒŒì¼ì´ ì†ìƒë˜ì—ˆìœ¼ë©´ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ
        download_dart_corpcode_file()
        return None

# ì¢…ëª©ì½”ë“œë¡œ DART íšŒì‚¬ì½”ë“œ ì°¾ê¸° (ìºì‹œëœ ZIP íŒŒì¼ ì‚¬ìš©)
def find_dart_corp_code(symbol):
    """ì¢…ëª©ì½”ë“œë¡œ DART íšŒì‚¬ì½”ë“œ ì°¾ê¸° (ìºì‹œëœ íŒŒì¼ ì‚¬ìš©)"""
    if not DART_API_KEY:
        return None
    
    try:
        # KRX ë¦¬ìŠ¤íŠ¸ì—ì„œ íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
        krx_list = fdr.StockListing('KRX')
        if krx_list is None or krx_list.empty:
            return None
        
        symbol_col = 'Code' if 'Code' in krx_list.columns else ('Symbol' if 'Symbol' in krx_list.columns else None)
        name_col = 'Name' if 'Name' in krx_list.columns else 'ì¢…ëª©ëª…'
        
        if not symbol_col:
            return None
        
        company_info = krx_list[krx_list[symbol_col] == symbol]
        if company_info.empty:
            return None
        
        company_name = company_info.iloc[0][name_col]
        print(f'íšŒì‚¬ëª… ì°¾ìŒ: {company_name} (ì¢…ëª©ì½”ë“œ: {symbol})')
        
        # ìºì‹œëœ ZIP íŒŒì¼ì—ì„œ XML ë¡œë“œ
        root = load_dart_corpcode_from_cache()
        if root is None:
            return None
        
        # íšŒì‚¬ëª…ìœ¼ë¡œ ê²€ìƒ‰
        for corp in root.findall('list'):
            corp_name_elem = corp.find('corp_name')
            corp_code_elem = corp.find('corp_code')
            
            if corp_name_elem is not None and corp_code_elem is not None:
                corp_name = corp_name_elem.text
                if corp_name and company_name in corp_name:
                    corp_code = corp_code_elem.text
                    if corp_code:
                        print(f'DART íšŒì‚¬ì½”ë“œ ì°¾ìŒ: {company_name} -> {corp_code}')
                        return corp_code
        
        print(f'DARTì—ì„œ íšŒì‚¬ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {company_name}')
        return None
    except Exception as e:
        print(f'DART íšŒì‚¬ì½”ë“œ ì°¾ê¸° ì˜¤ë¥˜: {e}')
        import traceback
        traceback.print_exc()
        return None

# í•œêµ­ ì£¼ì‹ ì¬ë¬´ì œí‘œ API ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/kr-stock/<symbol>/financials', methods=['GET'])
def get_kr_stock_financials(symbol):
    """í•œêµ­ ì£¼ì‹ ì¬ë¬´ì œí‘œ ì¡°íšŒ API (DART API ì‚¬ìš©)"""
    try:
        # ì‹¬ë³¼ ì •ë¦¬ (.KS ì œê±°)
        clean_symbol = symbol.replace('.KS', '').replace('.KQ', '')
        
        if not clean_symbol.isdigit() or len(clean_symbol) != 6:
            return jsonify({'error': 'ì˜¬ë°”ë¥¸ ì‹¬ë³¼ ì½”ë“œê°€ ì•„ë‹™ë‹ˆë‹¤.'}), 400

        try:
            chroma_financials = fetch_kr_financials_from_chroma(clean_symbol)
            if chroma_financials:
                print(f'[INFO] ChromaDB ì¬ë¬´ ë°ì´í„° ì‚¬ìš©(KR): {clean_symbol}')
                return jsonify(chroma_financials)
        except Exception as e:
            print(f'[WARN] ChromaDB ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨(KR): {clean_symbol} - {e}')
            import traceback
            traceback.print_exc()
        
        # DART APIë¡œ ì¬ë¬´ì œí‘œ ê°€ì ¸ì˜¤ê¸°
        if DART_API_KEY:
            try:
                corp_code = find_dart_corp_code(clean_symbol)
                if corp_code:
                    print(f'DART íšŒì‚¬ì½”ë“œ ì°¾ìŒ: {clean_symbol} -> {corp_code}')
                    financials = get_dart_financials(corp_code, clean_symbol)
                    if financials:
                        print(f'DART ì¬ë¬´ì œí‘œ ì¡°íšŒ ì„±ê³µ: {clean_symbol}')
                        return jsonify(financials)
                    else:
                        print(f'DART ì¬ë¬´ì œí‘œ ë°ì´í„° ì—†ìŒ: {clean_symbol}')
                else:
                    print(f'DART íšŒì‚¬ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {clean_symbol}')
            except Exception as e:
                print(f'DART API ì¬ë¬´ì œí‘œ ì¡°íšŒ ì˜¤ë¥˜: {e}')
                import traceback
                traceback.print_exc()
        
        # DART ì‹¤íŒ¨ ì‹œ FMP APIë¡œ í´ë°± (ëŒ€í˜•ì£¼ë§Œ ì§€ì›)
        print(f'FMP APIë¡œ í´ë°± ì‹œë„: {clean_symbol}')
        try:
            kr_symbol = f"{clean_symbol}.KS"
            url = f"https://financialmodelingprep.com/api/v3/income-statement/{kr_symbol}?period=quarter&limit=4&apikey={FMP_API_KEY}"
            print(f'FMP API í˜¸ì¶œ: {url[:80]}...')
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            income_statements = response.json()
            print(f'FMP API ì‘ë‹µ: {len(income_statements) if isinstance(income_statements, list) else "dict"}')
            
            if isinstance(income_statements, dict) and 'Error Message' in income_statements:
                raise Exception("FMP APIì—ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            if not income_statements or len(income_statements) == 0:
                return jsonify({
                    'revenue': [],
                    'netIncome': [],
                    'operatingIncome': [],
                    'chartData': []
                })
            
            # FMP ë°ì´í„° íŒŒì‹±
            chart_data = []
            revenue_data = []
            net_income_data = []
            operating_income_data = []
            
            for statement in reversed(income_statements):
                year = statement.get('calendarYear', '')
                quarter = statement.get('quarter', '')
                revenue = statement.get('revenue', 0) or 0
                net_income = statement.get('netIncome', 0) or 0
                operating_income = statement.get('operatingIncome', 0) or 0
                
                if year and quarter:
                    label = f"{year} Q{quarter}"
                else:
                    label = year if year else ''
                
                if label:
                    chart_data.append({
                        'year': label,
                        'revenue': revenue,
                        'netIncome': net_income,
                        'operatingIncome': operating_income
                    })
                    revenue_data.append({'year': label, 'value': revenue})
                    net_income_data.append({'year': label, 'value': net_income})
                    operating_income_data.append({'year': label, 'value': operating_income})
            
            latest = income_statements[0] if income_statements else {}
            latest_year = latest.get('calendarYear', '')
            latest_quarter = latest.get('quarter', '')
            latest_label = f"{latest_year} Q{latest_quarter}" if latest_year and latest_quarter else latest_year
            
            return jsonify({
                'revenue': revenue_data,
                'netIncome': net_income_data,
                'operatingIncome': operating_income_data,
                'chartData': chart_data,
                'latest': {
                    'revenue': latest.get('revenue', 0) or 0,
                    'netIncome': latest.get('netIncome', 0) or 0,
                    'operatingIncome': latest.get('operatingIncome', 0) or 0,
                    'year': latest_label
                }
            })
        except Exception as e:
            print(f'FMP í´ë°± ì˜¤ë¥˜: {e}')
        
        # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨
        return jsonify({
            'revenue': [],
            'netIncome': [],
            'operatingIncome': [],
            'chartData': []
        })
    except Exception as e:
        print(f'í•œêµ­ ì£¼ì‹ ì¬ë¬´ì œí‘œ API ì˜¤ë¥˜: {e}')
        return jsonify({
            'revenue': [],
            'netIncome': [],
            'operatingIncome': [],
            'chartData': []
        })

@app.route('/api/vision/analyze-image', methods=['POST'])
def analyze_image_route():
    """ì´ë¯¸ì§€ë¥¼ Vision + Geminië¡œ ë¶„ì„í•˜ì—¬ ì œí’ˆ/ë¸Œëœë“œ ì •ë³´ë¥¼ ë°˜í™˜"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'file í•„ë“œì— ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•´ì£¼ì„¸ìš”.'}), 400

        image_file = request.files['file']
        image_bytes = image_file.read()

        if not image_bytes:
            return jsonify({'error': 'ë¹ˆ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.'}), 400

        result = analyze_product_from_image(image_bytes)
        return jsonify(result)
    except Exception as e:
        print(f'[ERROR] Vision ë¶„ì„ ì‹¤íŒ¨: {e}')
        return jsonify({'error': f'ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}'}), 500

@app.route('/api/parse-stock-query', methods=['POST'])
def parse_stock_query():
    """ì…ë ¥ ë¬¸ì¥ì—ì„œ ì£¼ì‹ ê²€ìƒ‰ ì˜ë„ì™€ ê±°ë˜ì†Œ/í‹°ì»¤ ì¶”ì¶œ"""
    try:
        data = request.json or {}
        user_message = (data.get('message') or '').strip()
        history_entries = data.get('history') or []

        contents = []
        for entry in history_entries:
            try:
                role = entry.get('role')
                text = (entry.get('content') or '').strip()
            except AttributeError:
                continue
            if not text:
                continue
            if role == 'assistant':
                gemini_role = 'model'
            else:
                gemini_role = 'user'
            contents.append({
                "role": gemini_role,
                "parts": [{"text": text}]
            })

        contents.append({
            "role": "user",
            "parts": [{"text": user_message}]
        })

        if not user_message:
            return jsonify({'error': 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

        system_prompt = """ì—­í• : ì£¼ì‹/ETF ì§ˆì˜ íŒŒì„œ
ì…ë ¥ ë¬¸ì¥ì€ í•œêµ­ì–´Â·ì˜ì–´ í˜¼ìš©ì¼ ìˆ˜ ìˆë‹¤. ì¶œë ¥ì€ JSON(object) í•˜ë‚˜ë§Œ ë°˜í™˜í•œë‹¤.

í•„ìˆ˜ í•„ë“œ:
- is_stock_query: true/false
- stock_name: ì¢…ëª©ëª… ë¬¸ìì—´ (ëª¨ë¥´ë©´ null)
- is_korean: true/false/null (í•œêµ­ ìƒì¥ì£¼ì¸ì§€ ì—¬ë¶€)
- ticker: ìƒì¥ í‹°ì»¤ ë¬¸ìì—´ (ëª¨ë¥´ë©´ null)
- exchange: ê±°ë˜ì†Œ ë¬¸ìì—´ (ëª¨ë¥´ë©´ null)

íŒë‹¨ ê¸°ì¤€:
1. ë¬¸ì¥ì— 'ì£¼ê°€', 'ì£¼ì‹', 'ì •ë³´', 'ìƒí™©', 'ì–´ë•Œ', 'ë¶„ì„', 'íˆ¬ì', 'ê°€ê²©' ë“± ì£¼ì‹ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ is_stock_query=trueë¡œ ë³¸ë‹¤.
2. ëª…ì‹œì ìœ¼ë¡œ ë‹¤ë¥¸ ì˜ë„ê°€ ë³´ì¼ ë•Œë§Œ is_stock_query=falseë¥¼ ë°˜í™˜í•œë‹¤.
3. ì¢…ëª©ëª…ì„ ì¶”ì •í•  ë•ŒëŠ” ì„¸ê³„ ì£¼ìš” ìƒì¥ì‚¬ë¥¼ í­ë„“ê²Œ ê³ ë ¤í•˜ê³ , í•œêµ­ì–´ í‘œê¸°ë¥¼ ì˜ì–´ ê³µì‹ëª…ìœ¼ë¡œ ë³€í™˜í•œë‹¤.
   - ì˜ˆ: "ì˜¨ë‹¤ìŠ¤ í™€ë”©ìŠ¤" â†’ "Ondas Holdings", "ë ˆì¼ë¹„ì „" â†’ "Rail Vision".
4. í•œêµ­ ìƒì¥ ê¸°ì—…(í•œê¸€ ê¸°ì—…ëª…, 6ìë¦¬ ìˆ«ì, .KS/.KQ ë“±)ì´ë¼ê³  í™•ì‹ ë  ë•Œë§Œ is_korean=true. ì¡°ê¸ˆì´ë¼ë„ ë¶ˆí™•ì‹¤í•˜ë©´ null.
5. í•œêµ­ ìƒì¥ì‚¬ê°€ ì•„ë‹ˆë¼ê³  íŒë‹¨ë˜ë©´ is_korean=falseë¡œ ë‘ê³  stock_nameì€ ë°˜ë“œì‹œ ì˜ì–´ ê³µì‹ëª… ë˜ëŠ” í™•ì‹¤í•œ í‹°ì»¤ë¥¼ ë„£ëŠ”ë‹¤.
6. ticker, exchangeëŠ” í™•ì‹¤í•œ ê²½ìš°ë§Œ ì±„ìš´ë‹¤. ë¶ˆí™•ì‹¤í•˜ë©´ null.
7. ìì‹ ì´ í™•ì‹ í•  ìˆ˜ ì—†ìœ¼ë©´ stock_nameë„ nullë¡œ ë‘ê³  is_korean=null, ticker=null, exchange=nullì„ ìœ ì§€í•œë‹¤.
8. JSON ì™¸ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤.

ì‘ë‹µ ì˜ˆì‹œ:
{"is_stock_query": true, "stock_name": "Samsung Electronics", "is_korean": true, "ticker": "005930", "exchange": "KRX"}
{"is_stock_query": true, "stock_name": "Tesla", "is_korean": false, "ticker": "TSLA", "exchange": "NASDAQ"}
{"is_stock_query": true, "stock_name": "Ondas Holdings", "is_korean": false, "ticker": "ONDS", "exchange": "NASDAQ"}
{"is_stock_query": true, "stock_name": "Rail Vision", "is_korean": false, "ticker": "RVSN", "exchange": "NASDAQ"}
{"is_stock_query": false, "stock_name": null, "is_korean": null, "ticker": null, "exchange": null}
"""

        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        model_name = "gemini-2.5-pro"
        url = (
            "https://generativelanguage.googleapis.com/v1beta/models/"
            f"{model_name}:generateContent"
            f"?key={GEMINI_API_KEY}"
        )
        payload = {
            "contents": contents,
            "system_instruction": {
                "parts": [{"text": system_prompt}]
            },
            "generationConfig": {
                "temperature": 0,
                "topP": 0.1,
                "topK": 1,
                "responseMimeType": "application/json"
            }
        }
        ai_response_raw = requests.post(
            url,
            headers={"Content-Type": "application/json"},
            json=payload,
            timeout=20
        )
        ai_response_raw.raise_for_status()
        data_json = ai_response_raw.json()
        candidates = data_json.get("candidates", [])
        if not candidates:
            raise ValueError("Gemini ì‘ë‹µì— í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

        ai_text = ""
        for part in candidates[0].get("content", {}).get("parts", []):
            if "text" in part:
                ai_text += part["text"]

        result = json.loads(ai_text or "{}")

        # ê¸°ë³¸ í•„ë“œ ë³´ì •
        if "ticker" not in result:
            result["ticker"] = None
        if "exchange" not in result:
            result["exchange"] = None

        # í•œêµ­ ì£¼ì‹ íŒë‹¨ ì‹œ KRXì—ì„œ ê²€ì¦
        if (
            result.get("is_stock_query")
            and result.get("is_korean") is True
            and result.get("stock_name")
        ):
            try:
                check_symbol = search_kr_stock_symbol(result["stock_name"])
            except Exception:
                check_symbol = None

            if check_symbol:
                result["ticker"] = check_symbol
                result["exchange"] = "KRX"
            else:
                result["is_korean"] = False

        print(f"[AI íŒŒì„œ] ì…ë ¥: {user_message} -> {result}")
        return jsonify(result)
    except json.JSONDecodeError:
        print("[AI íŒŒì„œ] JSON íŒŒì‹± ì‹¤íŒ¨")
        return jsonify({
            "is_stock_query": False,
            "stock_name": None,
            "is_korean": None,
            "ticker": None,
            "exchange": None
        })
    except requests.RequestException as e:
        print(f"[AI íŒŒì„œ] Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return jsonify({
            "is_stock_query": False,
            "stock_name": None,
            "is_korean": None,
            "ticker": None,
            "exchange": None
        }), 500
    except Exception as e:
        print(f"[AI íŒŒì„œ] ì˜¤ë¥˜: {e}")
        return jsonify({
            "is_stock_query": False,
            "stock_name": None,
            "is_korean": None,
            "ticker": None,
            "exchange": None
        }), 500


@app.route('/api/test/chat', methods=['POST'])
def test_chat():
    """
    Gemini ê¸°ë³¸ ì‘ë‹µì„ í™•ì¸í•˜ê¸° ìœ„í•œ í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸.
    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—†ì´ ì‚¬ìš©ì ì…ë ¥ë§Œ ì „ë‹¬í•œë‹¤.
    """
    try:
        data = request.json or {}
        user_message = (data.get('message') or '').strip()

        if not user_message:
            return jsonify({'error': 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        model_name = "gemini-2.5-pro"
        url = (
            "https://generativelanguage.googleapis.com/v1beta/models/"
            f"{model_name}:generateContent"
            f"?key={GEMINI_API_KEY}"
        )

        payload = {
            "contents": [
                {
                    "role": "user",
                    "parts": [{"text": user_message}]
                }
            ]
        }

        ai_response = requests.post(
            url,
            headers={"Content-Type": "application/json"},
            json=payload,
            timeout=20
        )
        ai_response.raise_for_status()
        data_json = ai_response.json()

        candidates = data_json.get("candidates", [])
        if not candidates:
            raise ValueError("Gemini ì‘ë‹µì— í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

        reply_text = ""
        for part in candidates[0].get("content", {}).get("parts", []):
            if "text" in part:
                reply_text += part["text"]

        return jsonify({"reply": reply_text.strip()})
    except requests.RequestException as e:
        print(f"[í…ŒìŠ¤íŠ¸ ì±—ë´‡] Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return jsonify({"error": "ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."}), 500
    except Exception as e:
        print(f"[í…ŒìŠ¤íŠ¸ ì±—ë´‡] ì˜¤ë¥˜: {e}")
        return jsonify({"error": "ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}), 500


@app.route('/api/market-indices/<market>', methods=['GET'])
def get_market_indices(market):
    """êµ­ë‚´/ë¯¸êµ­ ì£¼ê°€ì§€ìˆ˜ ë°ì´í„° ë°˜í™˜"""
    try:
        if market == 'kr':
            # êµ­ë‚´ ì§€ìˆ˜: KOSPI, KOSDAQ, KOSPI200
            indices = ['KS11', 'KQ11', 'KS200']  # FinanceDataReader ì½”ë“œ
            index_names = {
                'KS11': 'ì½”ìŠ¤í”¼',
                'KQ11': 'ì½”ìŠ¤ë‹¥',
                'KS200': 'ì½”ìŠ¤í”¼200'
            }
        elif market == 'us':
            # ë¯¸êµ­ ì§€ìˆ˜: S&P 500, NASDAQ, Dow Jones
            indices = ['US500', 'IXIC', 'DJI']  # FinanceDataReader ì½”ë“œ
            index_names = {
                'US500': 'S&P 500',
                'IXIC': 'ë‚˜ìŠ¤ë‹¥',
                'DJI': 'ë‹¤ìš°ì¡´ìŠ¤'
            }
        else:
            return jsonify({'error': 'Invalid market'}), 400
        
        result = []
        today = datetime.now().date()
        
        for idx_code in indices:
            try:
                # ìµœê·¼ 2ì¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì „ì¼ ëŒ€ë¹„ ê³„ì‚°ìš©)
                df = fdr.DataReader(idx_code, today - timedelta(days=5), today)
                
                if df.empty:
                    continue
                
                # ìµœì‹  ë°ì´í„°
                latest = df.iloc[-1]
                prev = df.iloc[-2] if len(df) > 1 else latest
                
                current_value = float(latest['Close'])
                prev_value = float(prev['Close'])
                change = current_value - prev_value
                change_percent = (change / prev_value * 100) if prev_value != 0 else 0
                
                result.append({
                    'code': idx_code,
                    'name': index_names.get(idx_code, idx_code),
                    'value': round(current_value, 2),
                    'change': round(change, 2),
                    'changePercent': round(change_percent, 2)
                })
            except Exception as e:
                print(f'Error fetching {idx_code}: {e}')
                continue
        
        return jsonify({'indices': result})
    
    except Exception as e:
        print(f'Error in get_market_indices: {e}')
        return jsonify({'error': str(e)}), 500

@app.route('/api/top-stocks-by-market-cap', methods=['GET'])
def get_top_stocks_by_market_cap():
    """ì‹œê°€ì´ì•¡ ê¸°ì¤€ ìƒìœ„ 5ê°œ ì¢…ëª© ë°˜í™˜"""
    try:
        # KRX ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        krx_list = fdr.StockListing('KRX')
        
        if krx_list is None or krx_list.empty:
            return jsonify({'error': 'ì¢…ëª© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500
        
        # ì‹œê°€ì´ì•¡ ì»¬ëŸ¼ ì°¾ê¸° (ì˜ë¬¸/í•œê¸€ ëª¨ë‘ í™•ì¸)
        market_cap_col = None
        for col in ['Marcap', 'ì‹œê°€ì´ì•¡', 'MarketCap', 'market_cap']:
            if col in krx_list.columns:
                market_cap_col = col
                break
        
        if not market_cap_col:
            return jsonify({'error': 'ì‹œê°€ì´ì•¡ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500
        
        # ì¢…ëª©ëª…, ì¢…ëª©ì½”ë“œ ì»¬ëŸ¼ ì°¾ê¸°
        name_col = 'Name' if 'Name' in krx_list.columns else ('ì¢…ëª©ëª…' if 'ì¢…ëª©ëª…' in krx_list.columns else None)
        code_col = 'Code' if 'Code' in krx_list.columns else ('Symbol' if 'Symbol' in krx_list.columns else None)
        
        if not name_col or not code_col:
            return jsonify({'error': 'ì¢…ëª© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500
        
        # ì‹œê°€ì´ì•¡ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
        sorted_df = krx_list.sort_values(by=market_cap_col, ascending=False)
        
        # ìƒìœ„ 5ê°œ ì„ íƒ
        top_5 = sorted_df.head(5)
        
        result = []
        for _, row in top_5.iterrows():
            try:
                symbol = str(row[code_col]).zfill(6)  # 6ìë¦¬ ì¢…ëª©ì½”ë“œ
                name = str(row[name_col])
                market_cap = float(row[market_cap_col]) if pd.notna(row[market_cap_col]) else 0
                
                # í˜„ì¬ê°€ ê°€ì ¸ì˜¤ê¸°
                today = datetime.now().date()
                try:
                    price_df = fdr.DataReader(symbol, today - timedelta(days=2), today)
                    if not price_df.empty:
                        current_price = float(price_df.iloc[-1]['Close'])
                        prev_price = float(price_df.iloc[-2]['Close']) if len(price_df) > 1 else current_price
                        change = current_price - prev_price
                        change_percent = (change / prev_price * 100) if prev_price != 0 else 0
                    else:
                        current_price = 0
                        change = 0
                        change_percent = 0
                except:
                    current_price = 0
                    change = 0
                    change_percent = 0
                
                result.append({
                    'symbol': symbol,
                    'name': name,
                    'marketCap': round(market_cap / 100000000, 2),  # ì–µì› ë‹¨ìœ„ë¡œ ë³€í™˜
                    'price': round(current_price, 0),
                    'change': round(change, 0),
                    'changePercent': round(change_percent, 2)
                })
            except Exception as e:
                print(f'Error processing stock {row.get(name_col, "unknown")}: {e}')
                continue
        
        return jsonify({'stocks': result})
    
    except Exception as e:
        print(f'Error in get_top_stocks_by_market_cap: {e}')
        return jsonify({'error': str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'ok'})

if __name__ == '__main__':
    print('Python ì„œë²„ê°€ í¬íŠ¸ 5000ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.')
    app.run(host='0.0.0.0', port=5000, debug=True)

